import sys
import os
import streamlit as st
import json
import time
import importlib

# --- Page Config (Must be the first Streamlit command) ---
st.set_page_config(
    page_title="Jigyokei Hybrid System",
    page_icon="ğŸ‘‘",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- Path Setup ---
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '../..')))

# --- Module Reloading for Streamlit Cloud ---
import src.core.jigyokei_core
import src.api.schemas
import src.core.completion_checker
importlib.reload(src.core.jigyokei_core)
importlib.reload(src.api.schemas)
importlib.reload(src.core.completion_checker)

from src.core.jigyokei_core import AIInterviewer
from src.data.context_loader import ContextLoader

# --- Version Control ---
APP_VERSION = "3.3.1-multimodal-fix"

if "app_version" not in st.session_state or st.session_state.app_version != APP_VERSION:
    st.session_state.clear()
    st.session_state.app_version = APP_VERSION
    st.rerun()

# --- Initialize Managers ---
if "ai_interviewer" not in st.session_state:
    st.session_state.ai_interviewer = AIInterviewer()
else:
    # Check for outdated instance (missing 'analyze_history')
    # ã‚¯ãƒ©ã‚¹å®šç¾©ãŒãƒªãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã‚‚ã€ã‚»ãƒƒã‚·ãƒ§ãƒ³å†…ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã¯å¤ã„ã¾ã¾ãªã®ã§ã€ã“ã“ã§æ¤œçŸ¥ã—ã¦å†ç”Ÿæˆã™ã‚‹
    if not hasattr(st.session_state.ai_interviewer, "analyze_history"):
        st.warning("ğŸ”„ Upgrading AI Brain to latest version...")
        
        # Preserve old history
        old_history = getattr(st.session_state.ai_interviewer, "history", [])
        
        # Re-initialize with new class definition
        st.session_state.ai_interviewer = AIInterviewer()
        
        # Restore history
        # æ–°ã—ã„ã‚¯ãƒ©ã‚¹ã®load_historyã‚’ä½¿ã†ã‹ã€ç›´æ¥ä»£å…¥ã™ã‚‹ã‹ã€‚
        # ã“ã“ã§ã¯å®‰å…¨ã«ç›´æ¥ä»£å…¥ã—ã¤ã¤ã€Geminiã‚»ãƒƒã‚·ãƒ§ãƒ³å†æ§‹ç¯‰ã¯load_historyã«ä»»ã›ã‚‹ã®ãŒãƒ™ã‚¹ãƒˆã ãŒã€
        # ç°¡æ˜“çš„ã«load_historyã‚’å‘¼ã¶ã€‚
        if hasattr(st.session_state.ai_interviewer, "load_history"):
             st.session_state.ai_interviewer.load_history(old_history)
        else:
             st.session_state.ai_interviewer.history = old_history
             
        st.success("âœ… AI Brain Upgraded! Please reload one last time.")
        time.sleep(1)
        st.rerun()

if "context_loader" not in st.session_state:
    root_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '../..'))
    context_dir = os.path.join(root_dir, "data", "context")
    st.session_state.context_loader = ContextLoader(context_dir)

# --- Authentication ---
def check_password():
    if st.session_state.get("password_correct", False):
        return True

    def password_entered():
        if st.session_state["password"] == st.secrets["APP_PASSWORD"]:
            st.session_state["password_correct"] = True
            del st.session_state["password"]
        else:
            st.session_state["password_correct"] = False

    st.text_input("Password", type="password", on_change=password_entered, key="password")
    return False

if not check_password():
    st.stop()

# ==========================================
# Main App Logic
# ==========================================

# State Transition Helper
def change_mode(mode_name, persona_name=None):
    # Map legacy args to new nav selection
    target = "çµŒå–¶è€…ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼" # Default
    
    if mode_name == "Chat Mode (Interview)":
        if persona_name == "çµŒå–¶è€…": target = "çµŒå–¶è€…ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼"
        elif persona_name == "å¾“æ¥­å“¡": target = "å¾“æ¥­å“¡ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼"
        elif persona_name == "å•†å·¥ä¼šè·å“¡": target = "å•†å·¥ä¼šè·å“¡ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼"
    elif mode_name == "Main Consensus Room (Resolution)":
        target = "Main Consensus Room (å…¨ä½“åˆæ„)"
    elif mode_name == "Dashboard Mode (Progress)":
        target = "Dashboard Mode (Progress)"
         
    st.session_state.app_nav_selection = target

with st.sidebar:
    st.header("Jigyokei Hybrid System")
    st.caption("Cloud Edition â˜ï¸")
    st.text(f"Ver: {APP_VERSION}") # ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’å¸¸ã«è¡¨ç¤º
    
    # Navigation Selection
    if "app_nav_selection" not in st.session_state:
        st.session_state.app_nav_selection = "çµŒå–¶è€…ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼"

    # Determine current index for radio
    interview_options = ["çµŒå–¶è€…ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼", "å¾“æ¥­å“¡ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼", "å•†å·¥ä¼šè·å“¡ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼"]
    current_nav = st.session_state.app_nav_selection
    
    radio_index = 0
    if current_nav in interview_options:
        radio_index = interview_options.index(current_nav)
        
    # Callback to update state from radio
    def on_radio_change():
        st.session_state.app_nav_selection = st.session_state.nav_radio_key

    selected_interview = st.radio(
        "ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼é¸æŠ",
        interview_options,
        index=radio_index,
        key="nav_radio_key",
        on_change=on_radio_change
    )
    
    # Logic derivation (Internal)
    nav = st.session_state.app_nav_selection
    
    # --- State Tracking for Navigation Flux (Dashboard Return) ---
    if "last_chat_nav" not in st.session_state:
        st.session_state.last_chat_nav = "çµŒå–¶è€…ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼"

    valid_return_targets = [
        "çµŒå–¶è€…ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼", 
        "å¾“æ¥­å“¡ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼", 
        "å•†å·¥ä¼šè·å“¡ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼", 
        "Main Consensus Room (å…¨ä½“åˆæ„)"
    ]
    if nav in valid_return_targets:
        st.session_state.last_chat_nav = nav
    # -------------------------------------------------------------

    if nav == "çµŒå–¶è€…ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼":
        mode = "Chat Mode (Interview)"
        persona = "çµŒå–¶è€…"
    elif nav == "å¾“æ¥­å“¡ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼":
        mode = "Chat Mode (Interview)"
        persona = "å¾“æ¥­å“¡"
    elif nav == "å•†å·¥ä¼šè·å“¡ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼":
        mode = "Chat Mode (Interview)"
        persona = "å•†å·¥ä¼šè·å“¡"
    elif nav == "Main Consensus Room (å…¨ä½“åˆæ„)":
        mode = "Main Consensus Room (Resolution)"
        persona = "ç·åˆèª¿æ•´å½¹"
    elif nav == "Dashboard Mode (Progress)":
        mode = "Dashboard Mode (Progress)"
        persona = "Viewer"
    else: # Fallback
        mode = "Chat Mode (Interview)"
        persona = "çµŒå–¶è€…"

    # Manager Menu (Hidden by default)
    with st.expander("ç®¡ç†è€…ãƒ¡ãƒ‹ãƒ¥ãƒ¼", expanded=False):

        if st.button("å…¨ä½“åˆæ„ãƒ«ãƒ¼ãƒ  (Consensus)", use_container_width=True):
             st.session_state.app_nav_selection = "Main Consensus Room (å…¨ä½“åˆæ„)"
             st.rerun()
             
        if st.button("ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ (Progress)", use_container_width=True):
             st.session_state.app_nav_selection = "Dashboard Mode (Progress)"
             st.rerun()

        st.divider()
        st.caption("Data Management")
        
        # --- Upload (Import) ---
        import_owner_label = "ãƒ‡ãƒ¼ã‚¿æ‰€æœ‰è€… (ã‚¿ã‚°è£œå®Œç”¨)"
        import_owner = st.selectbox(
            import_owner_label, 
            ["è‡ªå‹• (Auto)", "çµŒå–¶è€…", "å¾“æ¥­å“¡", "å•†å·¥ä¼šè·å“¡"], 
            index=0,
            key="import_owner_select", # Changed key to avoid duplicate error if previously rendered? No, component moved.
            help="å¤ã„ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€éš›ã€èª°ã®ä¼šè©±ãƒ‡ãƒ¼ã‚¿ã‹æŒ‡å®šã—ã¾ã™ã€‚ã€Œè‡ªå‹•ã€ã®å ´åˆã¯ãƒ•ã‚¡ã‚¤ãƒ«å†…ã®æƒ…å ±ã‚’å„ªå…ˆã—ã¾ã™ã€‚"
        )
        
        uploaded_file = st.file_uploader("JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‰ãƒ©ãƒƒã‚°ï¼†ãƒ‰ãƒ­ãƒƒãƒ—", type=["json"])
        
        if uploaded_file:
            file_id = f"{uploaded_file.name}_{uploaded_file.size}"
            if st.session_state.get("last_loaded_file_id") != file_id:
                try:
                    uploaded_file.seek(0)
                    data = json.load(uploaded_file)
                    
                    # Tag Injection Logic
                    valid_history = [m for m in data.get("history", []) if isinstance(m, dict)]
                    
                    if import_owner != "è‡ªå‹• (Auto)":
                        for msg in valid_history:
                            if "persona" not in msg and msg.get("role") == "user":
                                msg["persona"] = import_owner
                            if "target_persona" not in msg and msg.get("role") == "model":
                                msg["target_persona"] = import_owner
                    
                    st.session_state.ai_interviewer.load_history(valid_history, merge=True)
                    st.session_state.loaded_msg_count = len(st.session_state.ai_interviewer.history)
                    st.session_state.last_loaded_file_id = file_id
                    
                    st.toast(f"âœ… ãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆã—ã¾ã—ãŸ ({import_owner})", icon="ğŸ“¥")
                    time.sleep(1)
                    st.rerun()
                except Exception as e:
                    st.error(f"Error loading JSON: {e}")

        # --- Download (Export) ---
        if st.session_state.ai_interviewer.history:
            # 1. Full Backup
            full_history_json = json.dumps({"history": st.session_state.ai_interviewer.history}, indent=2, ensure_ascii=False)
            st.download_button(
                label="ğŸ“¦ å…¨ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ (Backup All)",
                data=full_history_json,
                file_name=f"jigyokei_full_backup_{int(time.time())}.json",
                mime="application/json"
            )

            # 1.5 Draft Plan Export (Markdown) - Only if analyzed
            # TEMPORARY: Disabled Markdown Export due to Schema Migration (JigyokeiPlan -> ApplicationRoot)
            if False and "current_plan" in st.session_state and st.session_state.current_plan:
                plan_export = st.session_state.current_plan
                # Simple MD generation
                md_text = f"# äº‹æ¥­ç¶™ç¶šåŠ›å¼·åŒ–è¨ˆç”»ï¼ˆä¸‹æ›¸ãï¼‰\\n\\n"
                md_text += f"## åŸºæœ¬æƒ…å ±\\n- ä¼æ¥­å: {plan_export.basic_info.company_name}\\n- ä»£è¡¨è€…: {plan_export.basic_info.representative_name}\\n- ä½æ‰€: {plan_export.basic_info.address}\\n\\n"
                md_text += f"## äº‹æ¥­å†…å®¹\\n- é¡§å®¢: {plan_export.business_content.target_customers}\\n- å•†å“ãƒ»ã‚µãƒ¼ãƒ“ã‚¹: {plan_export.business_content.products_services}\\n- æä¾›æ–¹æ³•: {plan_export.business_content.delivery_methods}\\n- å¼·ã¿: {plan_export.business_content.core_competence}\\n\\n"
                md_text += f"## è¢«å®³æƒ³å®š (ãƒªã‚¹ã‚¯)\\n"
                for r in plan_export.disaster_risks:
                    md_text += f"- {r.risk_type}: {r.impact_description}\\n"
                md_text += f"\\n## äº‹å‰å¯¾ç­–\\n"
                for m in plan_export.pre_disaster_measures:
                    md_text += f"- {m.item}: {m.content} (æ‹…å½“: {m.in_charge})\\n"
                
                st.download_button(
                    label="ğŸ“ ä¸‹æ›¸ãã‚·ãƒ¼ãƒˆã‚’ä¿å­˜ (Markdown)",
                    data=md_text,
                    file_name=f"jigyokei_draft_{int(time.time())}.md",
                    mime="text/markdown",
                    help="è§£ææ¸ˆã¿ã®è¨ˆç”»æ›¸ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜ã—ã¾ã™ã€‚"
                )
            
            # 2. Persona Specific Export
            # Note: Need to access 'persona' variable which is derived LATER.
            # CRITICAL: We cannot access 'persona' here because it is defined AFTER this block.
            # Implication: We should calculate 'persona' inside the expander OR rely on session state if available.
            # BUT 'persona' depends on 'nav' which IS available (st.session_state.app_nav_selection).
            # Let's verify 'nav' logic.
             
             

# --- Main Area ---


if mode == "Chat Mode (Interview)":
    # 1. Dashboard Navigation & Header
    col_head1, col_head2 = st.columns([3, 1])
    with col_head1:
        st.title("ğŸ¤– AI Interviewer (Chat Mode)")
    with col_head2:
        st.button(
            "ğŸ“Š é€²æ—åº¦ã‚’ç¢ºèªã™ã‚‹",
            on_click=change_mode,
            args=("Dashboard Mode (Progress)",)
        )

    # User Metadata Inputs (Main Panel) - Always visible at top
    with st.container(border=True):
        st.caption(f"ğŸ“ {persona}æƒ…å ±å…¥åŠ›")
        col_u1, col_u2 = st.columns(2)
        with col_u1:
             pos_placeholder = "ä¾‹: ä»£è¡¨å–ç· å½¹"
             if persona == "å¾“æ¥­å“¡": pos_placeholder = "ä¾‹: ç¾å ´ç›£ç£"
             elif persona == "å•†å·¥ä¼šè·å“¡": pos_placeholder = "ä¾‹: çµŒå–¶æŒ‡å°å“¡"
             st.text_input("å½¹è· (Position)", key="user_position_input", placeholder=pos_placeholder)
        with col_u2:
             st.text_input("ãŠåå‰ (Name)", key="user_name_input", placeholder="ä¾‹: å±±ç”° å¤ªéƒ")

    # 2. Document Upload Area (Always Available)
    with st.expander("ğŸ“‚ è³‡æ–™ã®è¿½åŠ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ (Upload Documents)", expanded=not st.session_state.ai_interviewer.history):
        # Persona-specific Guidance
        upload_label = "è³‡æ–™ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ (PDF/ç”»åƒ)"
        if persona == "çµŒå–¶è€…":
            st.info("ğŸ¢ **çµŒå–¶è€…ã®æ–¹ã¸**: ä¼šç¤¾æ¡ˆå†…ã€äº‹æ¥­è¨ˆç”»æ›¸ã€ãƒã‚¶ãƒ¼ãƒ‰ãƒãƒƒãƒ—ãªã©")
            upload_label = "ğŸ¢ çµŒå–¶è€…ç”¨è³‡æ–™ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"
        elif persona == "å¾“æ¥­å“¡":
            st.info("ğŸ‘· **å¾“æ¥­å“¡ã®æ–¹ã¸**: æ¥­å‹™ãƒãƒ‹ãƒ¥ã‚¢ãƒ«ã€ç·Šæ€¥é€£çµ¡ç¶²ã€ç¾å ´å†™çœŸãªã©")
            upload_label = "ğŸ‘· ç¾å ´ãƒ»æ¥­å‹™è³‡æ–™ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"
        elif persona == "å•†å·¥ä¼šè·å“¡":
            st.info("ğŸ§‘â€ğŸ« **å•†å·¥ä¼šè·å“¡ã®æ–¹ã¸**: å…±æ¸ˆãƒ‘ãƒ³ãƒ•ãƒ¬ãƒƒãƒˆã€åœ°åŸŸé˜²ç½è¨ˆç”»ãªã©")
            upload_label = "ğŸ§‘â€ğŸ« æ”¯æ´ãƒ»åˆ¶åº¦è³‡æ–™ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"
        
        uploaded_refs = st.file_uploader(
            upload_label, 
            type=["pdf", "png", "jpg", "jpeg"], 
            accept_multiple_files=True,
            key=f"uploader_{persona}_{int(time.time())}" # Add timestamp to reset key slightly if needed
        )
        
        if uploaded_refs and st.button("ğŸš€ è³‡æ–™ã‚’èª­ã¿è¾¼ã‚€ (Process Files)"):
             with st.spinner("è³‡æ–™ã‚’è§£æä¸­..."):
                try:
                    count = st.session_state.ai_interviewer.process_files(uploaded_refs)
                    st.success(f"{count}ä»¶ã®è³‡æ–™ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸï¼")
                    time.sleep(1)
                    st.rerun()
                except Exception as e:
                    st.error(f"èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

    # 3. Chat Interface
    st.divider()
    
    # History Display
    if not st.session_state.ai_interviewer.history:
        st.markdown(
            "ğŸ‘‹ **ã“ã‚“ã«ã¡ã¯ã€‚äº‹æ¥­ç¶™ç¶šåŠ›å¼·åŒ–è¨ˆç”»ã®ç­–å®šã‚’æ”¯æ´ã—ã¾ã™ã€‚**\n\n"
            "ã¾ãšã¯ä¸Šã®ã€Œè³‡æ–™ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã€ã‹ã‚‰è³‡æ–™ã‚’èª­ã¿è¾¼ã¾ã›ã‚‹ã‹ã€"
            "ä¸‹ã®å…¥åŠ›æ¬„ã‹ã‚‰ä¼šè©±ã‚’å§‹ã‚ã¦ãã ã•ã„ã€‚"
        )
    
    # Helper to render a single message
    def render_message(msg, current_persona):
        if not isinstance(msg, dict): return
        role = msg["role"]
        msg_persona = msg.get("persona", "Unknown")
        target_persona = msg.get("target_persona")
        
        # Filtering Logic
        visible = False
        if role == "user" and msg_persona == current_persona:
            visible = True
        elif role == "model" and target_persona == current_persona:
            visible = True
        
        if visible:
            avatar = "ğŸ¤–" if role == "model" else "ğŸ‘¤"
            if msg_persona == "çµŒå–¶è€…": avatar = "ğŸ‘¨â€ğŸ’¼"
            elif msg_persona == "å¾“æ¥­å“¡": avatar = "ğŸ‘·"
            elif msg_persona == "å•†å·¥ä¼šè·å“¡": avatar = "ğŸ§‘â€ğŸ«"
            elif msg_persona == "AI Concierge": avatar = "ğŸ¤–"
            
            with st.chat_message(role, avatar=avatar):
                if role == "user":
                    st.caption(f"{msg_persona}")
                
                # Sanitize content
                import re
                display_content = re.sub(r'<suggestions>.*?</suggestions>', '', msg["content"], flags=re.DOTALL).strip()
                st.markdown(display_content)

                # Capture suggestions (only from model)
                if role == "model":
                    match = re.search(r'<suggestions>(.*?)</suggestions>', msg["content"], flags=re.DOTALL)
                    if match:
                        try:
                            st.session_state._temp_suggestions = json.loads(match.group(1))
                        except:
                            pass

    # Reset temp suggestions
    if "_temp_suggestions" in st.session_state:
        del st.session_state["_temp_suggestions"]

    history = st.session_state.ai_interviewer.history
    loaded_count = st.session_state.get("loaded_msg_count", 0)

    # 1. Past History (Collapsible)
    if loaded_count > 0:
        with st.expander("ğŸ•’ éå»ã®ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’è¡¨ç¤º (Loaded History)", expanded=False):
            for i in range(loaded_count):
                if i < len(history):
                     render_message(history[i], persona)

    # 2. New Session History
    for i in range(loaded_count, len(history)):
        render_message(history[i], persona)
    
    # Retrieve suggestions
    current_dynamic_suggestions = st.session_state.get("_temp_suggestions", None)
        
    # --- Resume Guidance (System Message) ---
    # Only show if loaded history exists and no new messages have been added yet
    if loaded_count > 0 and len(history) == loaded_count:
        with st.container(border=True):
            st.markdown(f"**ğŸ¤– System Notification**")
            st.write("ä»¥å‰ã®ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚ç¶šãã‹ã‚‰å§‹ã‚ã¾ã—ã‚‡ã†ã€‚")
            
            # Simple missing info heuristic or static guidance
            if persona == "çµŒå–¶è€…":
                st.caption("ğŸ’¡ **ãƒ’ãƒ³ãƒˆ**: ä¼šç¤¾æ¡ˆå†…ã‚„äº‹æ¥­è¨ˆç”»æ›¸ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã¨ã€å…¥åŠ›ã®æ‰‹é–“ãŒçœã‘ã¾ã™ã€‚")
            elif persona == "å¾“æ¥­å“¡":
                st.caption("ğŸ’¡ **ãƒ’ãƒ³ãƒˆ**: ç¾å ´ã®å†™çœŸã‚„æ¥­å‹™ãƒãƒ‹ãƒ¥ã‚¢ãƒ«ãŒã‚ã‚Œã°ã€ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
            elif persona == "å•†å·¥ä¼šè·å“¡":
                st.caption("ğŸ’¡ **ãƒ’ãƒ³ãƒˆ**: åœ°åŸŸé˜²ç½è¨ˆç”»ã‚„ãƒã‚¶ãƒ¼ãƒ‰ãƒãƒƒãƒ—ã®æƒ…å ±ã‚’å…±æœ‰ã—ã¦ãã ã•ã„ã€‚")

    # --- Next Action Suggestions (Above Chat Input) ---
    st.caption("ğŸ’¡ **Quick Replies:** (ã‚¯ãƒªãƒƒã‚¯ã§è¿”ä¿¡ãƒ»ãƒˆãƒ”ãƒƒã‚¯é¸æŠ)")
    suggestion_cols = st.columns(3)
    
    # ç°¡æ˜“çš„ãªãƒšãƒ«ã‚½ãƒŠåˆ¥ææ¡ˆãƒªã‚¹ãƒˆ (Fallback)
    fallback_map = {
        "çµŒå–¶è€…": ["äº‹æ¥­ã®å¼·ã¿ã«ã¤ã„ã¦", "è‡ªç„¶ç½å®³ã¸ã®æ‡¸å¿µ", "é‡è¦ãªè¨­å‚™ãƒ»è³‡ç”£"],
        "å¾“æ¥­å“¡": ["ç·Šæ€¥æ™‚ã®é€£çµ¡ä½“åˆ¶", "é¿é›£çµŒè·¯ã®ç¢ºèª", "é¡§å®¢å¯¾å¿œãƒãƒ‹ãƒ¥ã‚¢ãƒ«"],
        "å•†å·¥ä¼šè·å“¡": ["ãƒã‚¶ãƒ¼ãƒ‰ãƒãƒƒãƒ—ç¢ºèª", "æå®³ä¿é™ºã®åŠ å…¥çŠ¶æ³", "åœ°åŸŸé˜²ç½è¨ˆç”»ã¨ã®é€£æº"]
    }
    
    # Use dynamic if available, else fallback
    # Note: 'current_dynamic_suggestions' needs to be initialized before loop if we want to be safe, 
    # but practically we can just init it here if not found.
    # Actually, Python variable scope in script means 'current_dynamic_suggestions' from loop might be unbound if loop didn't run or define it.
    # Better to initialize it before loop. 
    # BUT, since I can't edit "before loop" easily in this chunk without big context, 
    # I will use a safe access pattern or `locals().get`. 
    
    # Just to be safe and clean, let's use the fallback lookup.
    # Dynamic suggestion logic
    dynamic_list = None
    if current_dynamic_suggestions:
        if isinstance(current_dynamic_suggestions, dict):
            dynamic_list = current_dynamic_suggestions.get("suggested_topics")
        elif isinstance(current_dynamic_suggestions, list):
            dynamic_list = current_dynamic_suggestions

    final_suggestions = dynamic_list if dynamic_list else fallback_map.get(persona, [])
    
    suggested_prompt = None
    
    if final_suggestions:
        for i, topic in enumerate(final_suggestions[:3]):
            if suggestion_cols[i].button(f"ğŸ—£ï¸ {topic}", use_container_width=True):
                suggested_prompt = topic

    # User Input
    chat_input_prompt = st.chat_input(f"{persona}ã¨ã—ã¦å›ç­”ã‚’å…¥åŠ›...")
    
    # Determine which prompt to use (Button click takes precedence, but st.chat_input is usually None if button clicked)
    # Note: Streamlit execution model means if button clicked, rerun happens, chat_input is None.
    final_prompt = suggested_prompt if suggested_prompt else chat_input_prompt

    if final_prompt:
        with st.chat_message("user", avatar="ğŸ‘¤"):
            st.markdown(final_prompt)
        
        # Prepare metadata for context
        user_name = st.session_state.get("user_name_input", "")
        user_position = st.session_state.get("user_position_input", "")
        user_data = {"name": user_name, "position": user_position}

        with st.chat_message("model", avatar="ğŸ¤–"):
            with st.spinner("AI is thinking..."):
                response = st.session_state.ai_interviewer.send_message(
                    final_prompt, 
                    persona=persona,
                    user_data=user_data
                )
                st.markdown(response)
                
                # Feedback Toast
                st.toast("ğŸ“ ä¼šè©±ãƒ­ã‚°ã‚’æ›´æ–°ã—ã¾ã—ãŸ (Conversation Log Updated)", icon="âœ…")
                time.sleep(1) # Wait for toast to be seen briefly
                st.rerun()
elif mode == "Dashboard Mode (Progress)":
    # Navigation Header for Dashboard
    col_dash_head1, col_dash_head2 = st.columns([3, 1])
    with col_dash_head1:
        st.title("ğŸ“Š Progress Dashboard")
    with col_dash_head2:
        # 3-Way Back Navigation
        st.button("â¬…ï¸ çµŒå–¶è€…ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼", on_click=change_mode, args=("Chat Mode (Interview)", "çµŒå–¶è€…"), use_container_width=True)
        st.button("â¬…ï¸ å¾“æ¥­å“¡ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼", on_click=change_mode, args=("Chat Mode (Interview)", "å¾“æ¥­å“¡"), use_container_width=True)
        st.button("â¬…ï¸ å•†å·¥ä¼šè·å“¡ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼", on_click=change_mode, args=("Chat Mode (Interview)", "å•†å·¥ä¼šè·å“¡"), use_container_width=True)

    st.info("ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‹ã‚‰äº‹æ¥­è¨ˆç”»æ›¸ã®å®Œæˆåº¦ã‚’è‡ªå‹•åˆ¤å®šã—ã¾ã™ã€‚")
    
    from src.api.schemas import ApplicationRoot
    
    # è§£æå®Ÿè¡Œãƒœã‚¿ãƒ³
    if st.button("è§£æã™ã‚‹", type="primary", use_container_width=True):
        st.info("ğŸš€ Process Started: Checking Modules...")
        
        # ã‚¹ãƒ”ãƒŠãƒ¼ã‚’ä½¿ã‚ãšã«é€æ¬¡å®Ÿè¡Œã‚’è¡¨ç¤º
        status_placeholder = st.empty()
        
        try:
            status_placeholder.text("â³ Importing Schema...")
            from src.api.schemas import ApplicationRoot
            
            status_placeholder.text("â³ Calling Gemini API (This may take 10-20s)...")
            extracted_data = st.session_state.ai_interviewer.analyze_history()
            
            status_placeholder.text(f"âœ… API Returned. Data Type: {type(extracted_data)}")
            
            if extracted_data:
                status_placeholder.text("â³ Validating data with Pydantic...")
                try:
                    plan = ApplicationRoot.model_validate(extracted_data)
                    st.session_state.current_plan = plan
                    status_placeholder.success("ğŸ‰ Analysis Complete!")
                except Exception as val_e:
                    status_placeholder.error(f"Validation Error: {val_e}")
                    st.json(extracted_data)
                    st.stop()
                
                # --- Quality Check & Logic (Pending Migration) ---
                # issues = plan.check_quality()
                # missing_fields = []
                # if issues: ...
                
                st.session_state.ai_interviewer.set_focus_fields([]) # Clear focus for now
                
                time.sleep(1)
                st.rerun()

            else:
                status_placeholder.warning("âš ï¸ No data extracted (Empty result received).")

        except Exception as e:
            status_placeholder.error(f"âŒ Critical Error: {e}")
            st.exception(e)
    
    # è§£æçµæœã®è¡¨ç¤º (Updated for ApplicationRoot key mapping)
    if "current_plan" in st.session_state:
        plan: ApplicationRoot = st.session_state.current_plan
        from src.core.completion_checker import CompletionChecker
        
        # Run Analysis
        result = CompletionChecker.analyze(plan)
        
        # --- 1. Status Banner & Header ---
        st.divider()
        st.subheader("ğŸ“Š Plan Progress Dashboard")
        
        col_m1, col_m2 = st.columns([1, 4])
        with col_m1:
            st.metric(label="Total Score", value=f"{result['total_score']} / 100")
            
        with col_m2:
            st.caption("ç”³è«‹å¿…é ˆé …ç›® (Mandatory) vs æ¨å¥¨é …ç›® (Recommended)")
            st.progress(result['mandatory_progress'])
            st.caption(f"Mandatory: {int(result['mandatory_progress']*100)}% Complete")
            
        # --- 2. Actionable Alerts (Missing Mandatory) ---
        if result['status'] != "success":
            with st.container(border=True): # Red/Error container simulation
                st.error("ğŸš¨ ç”³è«‹ã«å‘ã‘ã¦ã€ä»¥ä¸‹ã®å¿…é ˆé …ç›®ãŒä¸è¶³ã—ã¦ã„ã¾ã™")
                for item in result['missing_mandatory']:
                    st.markdown(f"- **{item['section']}**: {item['msg']}")
                
                # Action Buttons (Simulation)
                # Action Buttons (Fixed Logic)
                if st.button("ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ã‚¢ãƒ¼ã«ä¸è¶³é …ç›®ã‚’èã„ã¦ã‚‚ã‚‰ã†", type="primary", key="btn_ask_missing"):
                    # 1. Set Focus
                    missing_msgs = [m['msg'] for m in result['missing_mandatory']]
                    st.session_state.ai_interviewer.set_focus_fields(missing_msgs)
                    
                    # 2. Inject System/User Trigger (Optional but helpful)
                    # We want the AI to speak first ideally, or context to be set.
                    # For now, just focus setting is enough as the System Prompt checks focus fields.
                    
                    # 3. Switch Navigation to Chat (Correctly restoring last active persona)
                    st.session_state.app_nav_selection = st.session_state.get("last_chat_nav", "çµŒå–¶è€…ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼")
                    
                    # 4. Rerun to effect change
                    st.rerun()

        elif result['recommended_progress'] < 1.0:
            st.success("âœ… ç”³è«‹è¦ä»¶ã¯ã‚¯ãƒªã‚¢ã—ã¦ã„ã¾ã™ï¼ (ã•ã‚‰ã«è¨ˆç”»ã‚’å¼·åŒ–ã—ã¾ã—ã‚‡ã†)")
            with st.expander("ğŸ’¡ ã•ã‚‰ãªã‚‹å“è³ªå‘ä¸Šã®ãƒ’ãƒ³ãƒˆ (Recommended Actions)", expanded=True):
                for sug in result['suggestions']:
                    st.info(f"Suggestion: {sug}")

        else:
             st.balloons()
             st.success("ğŸ† Perfect! è¨ˆç”»ã¯å®Œç’§ã§ã™ã€‚ç”³è«‹ã®æº–å‚™ãŒæ•´ã„ã¾ã—ãŸã€‚")

        # --- 3. Section Breakdown (Tabs) ---
        st.divider()
        tab1, tab2, tab3, tab4 = st.tabs(["ğŸ›¡ï¸ å¯¾ç­– (Measures)", "ğŸš¨ åˆå‹•ãƒ»ä½“åˆ¶", "ğŸ¢ åŸºæœ¬ãƒ»äº‹æ¥­", "ğŸ’° è³‡é‡‘ãƒ»ãã®ä»–"])
        
        with tab1:
            st.caption(f"äº‹å‰å¯¾ç­–: {result['counts']['measures']}ä»¶ç™»éŒ²æ¸ˆ")
            if plan.measures:
                st.table([m.model_dump() for m in plan.measures])
            else:
                st.info("å¯¾ç­–ãŒã¾ã ç™»éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
                
        with tab2:
            st.caption(f"åˆå‹•å¯¾å¿œ: {result['counts']['procedures']}ä»¶ç™»éŒ²æ¸ˆ")
            if plan.response_procedures:
                st.table([m.model_dump() for m in plan.response_procedures])
            else:
                st.info("åˆå‹•å¯¾å¿œãŒæœªç™»éŒ²ã§ã™ã€‚")

        with tab3:
            col3a, col3b = st.columns(2)
            with col3a:
                st.caption("åŸºæœ¬æƒ…å ±")
                st.json(plan.basic_info.model_dump(exclude_none=True))
            with col3b:
                st.caption("äº‹æ¥­æ¦‚è¦ãƒ»ç½å®³æƒ³å®š")
                st.write(f"**Assumption:** {plan.goals.disaster_scenario.disaster_assumption}")
                st.write(f"**Overview:** {plan.goals.business_overview}")
        
        with tab4:
             st.caption("è³‡é‡‘è¨ˆç”»")
             if plan.financial_plan.items:
                 st.table([i.model_dump() for i in plan.financial_plan.items])
             else:
                 st.warning("è³‡é‡‘è¨ˆç”»ãŒæœªå…¥åŠ›ã§ã™ã€‚")
                 
             st.caption("è¨­å‚™ãƒªã‚¹ãƒˆ (ç¨åˆ¶å„ªé‡)")
             if plan.equipment.items:
                 st.table([i.model_dump() for i in plan.equipment.items])
             else:
                 st.info("è¨­å‚™ãƒªã‚¹ãƒˆãªã— (ä»»æ„)")

        # --- 4. Sidebar Tools (Injected here dynamically or rely on static layout) ---
        # Note: Sidebar is already rendered at top of script. We can add to it here or just leave as is.
        # Adding a dedicated "Tools" expander in main area for visibility
        with st.expander("ğŸ› ï¸ ãŠå½¹ç«‹ã¡ãƒ„ãƒ¼ãƒ« (External Tools)"):
            c1, c2, c3 = st.columns(3)
            c1.link_button("ğŸŒ ãƒã‚¶ãƒ¼ãƒ‰ãƒãƒƒãƒ—ãƒãƒ¼ã‚¿ãƒ«", "https://disaportal.gsi.go.jp/")
            c2.link_button("ğŸ“‰ J-SHIS åœ°éœ‡äºˆæ¸¬", "https://www.j-shis.bosai.go.jp/")
            c3.link_button("ğŸ’´ ãƒªã‚¹ã‚¯ãƒ•ã‚¡ã‚¤ãƒŠãƒ³ã‚¹", "https://www.smrj.go.jp/sme/disaster/kyoujinka/")

    else:
        st.info("â˜ï¸ Click the button to analyze current chat history.")

    st.divider()
    with st.expander("Show Raw Chat History"):
        st.json(st.session_state.ai_interviewer.history)

elif mode == "Main Consensus Room (Resolution)":
    st.title("âš–ï¸ Consensus Room (å…¨ä½“åˆæ„)")
    st.caption("å„ãƒšãƒ«ã‚½ãƒŠã®æ„è¦‹ã‚’èª¿æ•´ã—ã€æœ€çµ‚çš„ãªæ–¹é‡ã‚’æ±ºå®šã—ã¾ã™ã€‚")
    
    # Conflict Detection
    with st.expander("ğŸ§ çŸ›ç›¾ãƒ»æœªåˆæ„äº‹é …ã®æ¤œçŸ¥ (Conflict Detection)", expanded=True):
        if st.button("çŸ›ç›¾ã‚’å†ã‚¹ã‚­ãƒ£ãƒ³ã™ã‚‹", type="primary"):
            with st.spinner("Analyzing conflicts..."):
                conflicts = st.session_state.ai_interviewer.detect_conflicts()
                st.session_state._conflicts_cache = conflicts
        
        # Retrieve cache
        current_conflicts_data = st.session_state.get("_conflicts_cache", {})
        current_conflicts = current_conflicts_data.get("conflicts", [])
        
        if current_conflicts:
            st.warning(f"{len(current_conflicts)}ä»¶ã®çŸ›ç›¾ã¾ãŸã¯æœªåˆæ„äº‹é …ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚")
            for i, c in enumerate(current_conflicts):
                st.markdown(f"#### {i+1}. {c.get('topic', 'Topic')}")
                col1, col2 = st.columns(2)
                with col1:
                    st.info(f"**A: {c.get('persona_A')}**\n\n{c.get('statement_A')}")
                with col2:
                    st.info(f"**B: {c.get('persona_B')}**\n\n{c.get('statement_B')}")
                st.success(f"ğŸ’¡ **AI Suggestion**: {c.get('suggestion')}")
                st.divider()
        else:
             st.info("çŸ›ç›¾ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ (æœªã‚¹ã‚­ãƒ£ãƒ³ã¾ãŸã¯è§£æ¶ˆæ¸ˆã¿)")

    st.divider()
    st.subheader("ğŸ’¬ å…¨ä½“æ–¹é‡ã®æ±ºå®š")
    
    # Chat History
    history = st.session_state.ai_interviewer.history
    
    # Show history using rendered helper
    for i in range(len(history)):
         render_message(history[i], "ç·åˆèª¿æ•´å½¹") 
    
    # Input
    if prompt := st.chat_input("å…¨ä½“æ–¹é‡ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ (ä¾‹: é¿é›£å ´æ‰€ã¯é«˜å°ã®å…¬åœ’ã¨ã—ã¾ã™)"):
         with st.chat_message("user", avatar="ğŸ‘¤"):
            st.markdown(prompt)
         
         # Metadata
         user_name = st.session_state.get("user_name_input", "")
         user_position = st.session_state.get("user_position_input", "")
         user_data = {"name": user_name, "position": user_position}
         
         with st.chat_message("model", avatar="ğŸ¤–"):
            with st.spinner("AI Facilitator is recording..."):
                response = st.session_state.ai_interviewer.send_message(
                    prompt, 
                    persona="ç·åˆèª¿æ•´å½¹",
                    user_data=user_data
                )
                st.markdown(response)
                st.rerun()
