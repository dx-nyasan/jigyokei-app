import sys
import os
import streamlit as st
import json
import time
import importlib

# --- Page Config (Must be the first Streamlit command) ---
st.set_page_config(
    page_title="Jigyokei Hybrid System",
    page_icon="ğŸ‘‘",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- Path Setup ---
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '../..')))

# --- Module Reloading for Streamlit Cloud ---
import src.core.jigyokei_core
import src.api.schemas
import src.core.completion_checker
importlib.reload(src.core.jigyokei_core)
importlib.reload(src.api.schemas)
importlib.reload(src.core.completion_checker)

from src.core.jigyokei_core import AIInterviewer
from src.data.context_loader import ContextLoader

# --- Version Control ---
APP_VERSION = "3.3.1-multimodal-fix"

if "app_version" not in st.session_state or st.session_state.app_version != APP_VERSION:
    st.session_state.clear()
    st.session_state.app_version = APP_VERSION
    st.rerun()

# --- Initialize Managers ---
if "ai_interviewer" not in st.session_state:
    st.session_state.ai_interviewer = AIInterviewer()
else:
    # Check for outdated instance (missing 'analyze_history')
    # ã‚¯ãƒ©ã‚¹å®šç¾©ãŒãƒªãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã‚‚ã€ã‚»ãƒƒã‚·ãƒ§ãƒ³å†…ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã¯å¤ã„ã¾ã¾ãªã®ã§ã€ã“ã“ã§æ¤œçŸ¥ã—ã¦å†ç”Ÿæˆã™ã‚‹
    if not hasattr(st.session_state.ai_interviewer, "analyze_history"):
        st.warning("ğŸ”„ Upgrading AI Brain to latest version...")
        
        # Preserve old history
        old_history = getattr(st.session_state.ai_interviewer, "history", [])
        
        # Re-initialize with new class definition
        st.session_state.ai_interviewer = AIInterviewer()
        
        # Restore history
        # æ–°ã—ã„ã‚¯ãƒ©ã‚¹ã®load_historyã‚’ä½¿ã†ã‹ã€ç›´æ¥ä»£å…¥ã™ã‚‹ã‹ã€‚
        # ã“ã“ã§ã¯å®‰å…¨ã«ç›´æ¥ä»£å…¥ã—ã¤ã¤ã€Geminiã‚»ãƒƒã‚·ãƒ§ãƒ³å†æ§‹ç¯‰ã¯load_historyã«ä»»ã›ã‚‹ã®ãŒãƒ™ã‚¹ãƒˆã ãŒã€
        # ç°¡æ˜“çš„ã«load_historyã‚’å‘¼ã¶ã€‚
        if hasattr(st.session_state.ai_interviewer, "load_history"):
             st.session_state.ai_interviewer.load_history(old_history)
        else:
             st.session_state.ai_interviewer.history = old_history
             
        st.success("âœ… AI Brain Upgraded! Please reload one last time.")
        time.sleep(1)
        st.rerun()

if "context_loader" not in st.session_state:
    root_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '../..'))
    context_dir = os.path.join(root_dir, "data", "context")
    st.session_state.context_loader = ContextLoader(context_dir)

# --- Authentication ---
def check_password():
    if st.session_state.get("password_correct", False):
        return True

    def password_entered():
        if st.session_state["password"] == st.secrets["APP_PASSWORD"]:
            st.session_state["password_correct"] = True
            del st.session_state["password"]
        else:
            st.session_state["password_correct"] = False

    st.text_input("Password", type="password", on_change=password_entered, key="password")
    return False

if not check_password():
    st.stop()

# ==========================================
# Main App Logic
# ==========================================

# State Transition Helper
def change_mode(mode_name, persona_name=None):
    # Map legacy args to new nav selection
    target = "çµŒå–¶è€…ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼" # Default
    
    if mode_name == "Chat Mode (Interview)":
        if persona_name == "çµŒå–¶è€…": target = "çµŒå–¶è€…ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼"
        elif persona_name == "å¾“æ¥­å“¡": target = "å¾“æ¥­å“¡ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼"
        elif persona_name == "å•†å·¥ä¼šè·å“¡": target = "å•†å·¥ä¼šè·å“¡ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼"
    elif mode_name == "Main Consensus Room (Resolution)":
        target = "Main Consensus Room (å…¨ä½“åˆæ„)"
    elif mode_name == "Dashboard Mode (Progress)":
        target = "Dashboard Mode (Progress)"
         
    st.session_state.app_nav_selection = target

with st.sidebar:
    st.header("Jigyokei Hybrid System")
    st.caption("Cloud Edition â˜ï¸")
    st.text(f"Ver: {APP_VERSION}") # ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’å¸¸ã«è¡¨ç¤º
    
    # Navigation Selection
    if "app_nav_selection" not in st.session_state:
        st.session_state.app_nav_selection = "çµŒå–¶è€…ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼"

    # Determine current index for radio
    interview_options = ["çµŒå–¶è€…ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼", "å¾“æ¥­å“¡ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼", "å•†å·¥ä¼šè·å“¡ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼"]
    current_nav = st.session_state.app_nav_selection
    
    radio_index = 0
    if current_nav in interview_options:
        radio_index = interview_options.index(current_nav)
        
    # Callback to update state from radio
    def on_radio_change():
        st.session_state.app_nav_selection = st.session_state.nav_radio_key

    selected_interview = st.radio(
        "ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼é¸æŠ",
        interview_options,
        index=radio_index,
        key="nav_radio_key",
        on_change=on_radio_change
    )
    
    # Logic derivation (Internal)
    nav = st.session_state.app_nav_selection
    
    # --- State Tracking for Navigation Flux (Dashboard Return) ---
    if "last_chat_nav" not in st.session_state:
        st.session_state.last_chat_nav = "çµŒå–¶è€…ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼"

    valid_return_targets = [
        "çµŒå–¶è€…ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼", 
        "å¾“æ¥­å“¡ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼", 
        "å•†å·¥ä¼šè·å“¡ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼", 
        "Main Consensus Room (å…¨ä½“åˆæ„)"
    ]
    if nav in valid_return_targets:
        st.session_state.last_chat_nav = nav
    # -------------------------------------------------------------

    if nav == "çµŒå–¶è€…ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼":
        mode = "Chat Mode (Interview)"
        persona = "çµŒå–¶è€…"
    elif nav == "å¾“æ¥­å“¡ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼":
        mode = "Chat Mode (Interview)"
        persona = "å¾“æ¥­å“¡"
    elif nav == "å•†å·¥ä¼šè·å“¡ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼":
        mode = "Chat Mode (Interview)"
        persona = "å•†å·¥ä¼šè·å“¡"
    elif nav == "Main Consensus Room (å…¨ä½“åˆæ„)":
        mode = "Main Consensus Room (Resolution)"
        persona = "ç·åˆèª¿æ•´å½¹"
    elif nav == "Dashboard Mode (Progress)":
        mode = "Dashboard Mode (Progress)"
        persona = "Viewer"
    else: # Fallback
        mode = "Chat Mode (Interview)"
        persona = "çµŒå–¶è€…"

    # Manager Menu (Hidden by default)
    with st.expander("ç®¡ç†è€…ãƒ¡ãƒ‹ãƒ¥ãƒ¼", expanded=False):

        if st.button("å…¨ä½“åˆæ„ãƒ«ãƒ¼ãƒ  (Consensus)", use_container_width=True):
             st.session_state.app_nav_selection = "Main Consensus Room (å…¨ä½“åˆæ„)"
             st.rerun()
             
        if st.button("ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ (Progress)", use_container_width=True):
             st.session_state.app_nav_selection = "Dashboard Mode (Progress)"
             st.rerun()

        st.divider()
        st.caption("Data Management")
        
        # --- Upload (Import) ---
        import_owner_label = "ãƒ‡ãƒ¼ã‚¿æ‰€æœ‰è€… (ã‚¿ã‚°è£œå®Œç”¨)"
        import_owner = st.selectbox(
            import_owner_label, 
            ["è‡ªå‹• (Auto)", "çµŒå–¶è€…", "å¾“æ¥­å“¡", "å•†å·¥ä¼šè·å“¡"], 
            index=0,
            key="import_owner_select", # Changed key to avoid duplicate error if previously rendered? No, component moved.
            help="å¤ã„ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€éš›ã€èª°ã®ä¼šè©±ãƒ‡ãƒ¼ã‚¿ã‹æŒ‡å®šã—ã¾ã™ã€‚ã€Œè‡ªå‹•ã€ã®å ´åˆã¯ãƒ•ã‚¡ã‚¤ãƒ«å†…ã®æƒ…å ±ã‚’å„ªå…ˆã—ã¾ã™ã€‚"
        )
        
        uploaded_file = st.file_uploader("JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‰ãƒ©ãƒƒã‚°ï¼†ãƒ‰ãƒ­ãƒƒãƒ—", type=["json"])
        
        if uploaded_file:
            file_id = f"{uploaded_file.name}_{uploaded_file.size}"
            if st.session_state.get("last_loaded_file_id") != file_id:
                try:
                    uploaded_file.seek(0)
                    data = json.load(uploaded_file)
                    
                    # Handle if data is a list (e.g. raw history list or basic_scenario)
                    if isinstance(data, list):
                        # Check if it looks like a valid history list (items must be dicts with 'role' and 'content')
                        if all(isinstance(m, dict) and "role" in m and "content" in m for m in data):
                             valid_history = data
                             if import_owner != "è‡ªå‹• (Auto)":
                                for msg in valid_history:
                                    if "persona" not in msg: msg["persona"] = import_owner
                                    if "target_persona" not in msg and msg.get("role") == "model": msg["target_persona"] = import_owner
                             
                             st.session_state.ai_interviewer.load_history(valid_history, merge=True)
                             st.session_state.loaded_msg_count = len(st.session_state.ai_interviewer.history)
                             st.toast(f"âœ… ä¼šè©±å±¥æ­´(ãƒªã‚¹ãƒˆå½¢å¼)ã‚’çµ±åˆã—ã¾ã—ãŸ ({len(valid_history)}ä»¶)", icon="ğŸ“¥")
                        else:
                             st.warning("âš ï¸ èª­ã¿è¾¼ã‚ã‚‹ãƒ‡ãƒ¼ã‚¿å½¢å¼ã§ã¯ã‚ã‚Šã¾ã›ã‚“ (å¯¾å¿œå½¢å¼: äº‹æ¥­è¨ˆç”»JSON, ã¾ãŸã¯ä¼šè©±å±¥æ­´ãƒªã‚¹ãƒˆ)")
                    
                    elif isinstance(data, dict):
                        # 1. History Loading Logic (Existing Wrapper)
                        if "history" in data:
                            valid_history = [m for m in data.get("history", []) if isinstance(m, dict)]
                            
                            if import_owner != "è‡ªå‹• (Auto)":
                                for msg in valid_history:
                                    if "persona" not in msg and msg.get("role") == "user":
                                        msg["persona"] = import_owner
                                    if "target_persona" not in msg and msg.get("role") == "model":
                                        msg["target_persona"] = import_owner
                            
                            st.session_state.ai_interviewer.load_history(valid_history, merge=True)
                            st.session_state.loaded_msg_count = len(st.session_state.ai_interviewer.history)
                            st.toast(f"âœ… ä¼šè©±å±¥æ­´ã‚’çµ±åˆã—ã¾ã—ãŸ ({len(valid_history)}ä»¶)", icon="ğŸ“¥")

                        # 2. Direct Plan Loading Logic (New for Test Data)
                        # Check if 'basic_info' or 'goals' (key fields of ApplicationRoot) exists
                        elif "basic_info" in data or "goals" in data:
                            from src.api.schemas import ApplicationRoot
                            try:
                                # Attempt to validate and load as current plan
                                # Note: validate might fail if partial data, so we might need construct=True or partial validation
                                # But let's try strict first as user said "test data"
                                plan = ApplicationRoot.model_validate(data)
                                st.session_state.current_plan = plan
                                st.toast("âœ… äº‹æ¥­è¨ˆç”»ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ (Direct Load)", icon="ğŸ“„")
                            except Exception as val_e:
                                st.warning(f"ãƒ‡ãƒ¼ã‚¿æ§‹é€ èª­ã¿è¾¼ã¿è­¦å‘Š: {val_e}")
                                # Fallback: Load as dict anyway for debugging
                                # st.session_state.current_plan = ApplicationRoot.construct(**data) 
                                pass
                        
                        else:
                            st.warning("âš ï¸ èª­ã¿è¾¼ã‚ã‚‹ãƒ‡ãƒ¼ã‚¿å½¢å¼ã§ã¯ã‚ã‚Šã¾ã›ã‚“ (history, basic_info, goals ã‚­ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“)")
                    else:
                         st.warning("âš ï¸ JSONå½¢å¼ãŒç„¡åŠ¹ã§ã™")

                    st.session_state.last_loaded_file_id = file_id
                    time.sleep(1)
                    st.rerun()
                except Exception as e:
                    st.error(f"Error loading JSON: {e}")

        # --- Download (Export) ---
        if st.session_state.ai_interviewer.history:
            # 1. Full Backup
            full_history_json = json.dumps({"history": st.session_state.ai_interviewer.history}, indent=2, ensure_ascii=False)
            st.download_button(
                label="ğŸ“¦ å…¨ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ (Backup All)",
                data=full_history_json,
                file_name=f"jigyokei_full_backup_{int(time.time())}.json",
                mime="application/json"
            )

            # 1.5 Draft Plan Export (Markdown) - Only if analyzed
            # TEMPORARY: Disabled Markdown Export due to Schema Migration (JigyokeiPlan -> ApplicationRoot)
            if False and "current_plan" in st.session_state and st.session_state.current_plan:
                plan_export = st.session_state.current_plan
                # Simple MD generation
                md_text = f"# äº‹æ¥­ç¶™ç¶šåŠ›å¼·åŒ–è¨ˆç”»ï¼ˆä¸‹æ›¸ãï¼‰\\n\\n"
                md_text += f"## åŸºæœ¬æƒ…å ±\\n- ä¼æ¥­å: {plan_export.basic_info.company_name}\\n- ä»£è¡¨è€…: {plan_export.basic_info.representative_name}\\n- ä½æ‰€: {plan_export.basic_info.address}\\n\\n"
                md_text += f"## äº‹æ¥­å†…å®¹\\n- é¡§å®¢: {plan_export.business_content.target_customers}\\n- å•†å“ãƒ»ã‚µãƒ¼ãƒ“ã‚¹: {plan_export.business_content.products_services}\\n- æä¾›æ–¹æ³•: {plan_export.business_content.delivery_methods}\\n- å¼·ã¿: {plan_export.business_content.core_competence}\\n\\n"
                md_text += f"## è¢«å®³æƒ³å®š (ãƒªã‚¹ã‚¯)\\n"
                for r in plan_export.disaster_risks:
                    md_text += f"- {r.risk_type}: {r.impact_description}\\n"
                md_text += f"\\n## äº‹å‰å¯¾ç­–\\n"
                for m in plan_export.pre_disaster_measures:
                    md_text += f"- {m.item}: {m.content} (æ‹…å½“: {m.in_charge})\\n"
                
                st.download_button(
                    label="ğŸ“ ä¸‹æ›¸ãã‚·ãƒ¼ãƒˆã‚’ä¿å­˜ (Markdown)",
                    data=md_text,
                    file_name=f"jigyokei_draft_{int(time.time())}.md",
                    mime="text/markdown",
                    help="è§£ææ¸ˆã¿ã®è¨ˆç”»æ›¸ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜ã—ã¾ã™ã€‚"
                )
            
            # 2. Persona Specific Export
            # Note: Need to access 'persona' variable which is derived LATER.
            # CRITICAL: We cannot access 'persona' here because it is defined AFTER this block.
            # Implication: We should calculate 'persona' inside the expander OR rely on session state if available.
            # BUT 'persona' depends on 'nav' which IS available (st.session_state.app_nav_selection).
            # Let's verify 'nav' logic.
             
             

# --- Main Area ---


if mode == "Chat Mode (Interview)":
    # 1. Dashboard Navigation & Header
    col_head1, col_head2 = st.columns([3, 1])
    with col_head1:
        st.title("ğŸ¤– AI Interviewer (Chat Mode)")
    with col_head2:
        st.button(
            "ğŸ“Š é€²æ—åº¦ã‚’ç¢ºèªã™ã‚‹",
            on_click=change_mode,
            args=("Dashboard Mode (Progress)",)
        )

    # User Metadata Inputs (Main Panel) - Always visible at top
    with st.container(border=True):
        st.caption(f"ğŸ“ {persona}æƒ…å ±å…¥åŠ›")
        col_u1, col_u2 = st.columns(2)
        with col_u1:
             pos_placeholder = "ä¾‹: ä»£è¡¨å–ç· å½¹"
             if persona == "å¾“æ¥­å“¡": pos_placeholder = "ä¾‹: ç¾å ´ç›£ç£"
             elif persona == "å•†å·¥ä¼šè·å“¡": pos_placeholder = "ä¾‹: çµŒå–¶æŒ‡å°å“¡"
             st.text_input("å½¹è· (Position)", key="user_position_input", placeholder=pos_placeholder)
        with col_u2:
             st.text_input("ãŠåå‰ (Name)", key="user_name_input", placeholder="ä¾‹: å±±ç”° å¤ªéƒ")

    # 2. Document Upload Area (Always Available)
    with st.expander("ğŸ“‚ è³‡æ–™ã®è¿½åŠ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ (Upload Documents)", expanded=not st.session_state.ai_interviewer.history):
        # Persona-specific Guidance
        upload_label = "è³‡æ–™ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ (PDF/ç”»åƒ)"
        if persona == "çµŒå–¶è€…":
            st.info("ğŸ¢ **çµŒå–¶è€…ã®æ–¹ã¸**: ä¼šç¤¾æ¡ˆå†…ã€äº‹æ¥­è¨ˆç”»æ›¸ã€ãƒã‚¶ãƒ¼ãƒ‰ãƒãƒƒãƒ—ãªã©")
            upload_label = "ğŸ¢ çµŒå–¶è€…ç”¨è³‡æ–™ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"
        elif persona == "å¾“æ¥­å“¡":
            st.info("ğŸ‘· **å¾“æ¥­å“¡ã®æ–¹ã¸**: æ¥­å‹™ãƒãƒ‹ãƒ¥ã‚¢ãƒ«ã€ç·Šæ€¥é€£çµ¡ç¶²ã€ç¾å ´å†™çœŸãªã©")
            upload_label = "ğŸ‘· ç¾å ´ãƒ»æ¥­å‹™è³‡æ–™ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"
        elif persona == "å•†å·¥ä¼šè·å“¡":
            st.info("ğŸ§‘â€ğŸ« **å•†å·¥ä¼šè·å“¡ã®æ–¹ã¸**: å…±æ¸ˆãƒ‘ãƒ³ãƒ•ãƒ¬ãƒƒãƒˆã€åœ°åŸŸé˜²ç½è¨ˆç”»ãªã©")
            upload_label = "ğŸ§‘â€ğŸ« æ”¯æ´ãƒ»åˆ¶åº¦è³‡æ–™ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"
        
        uploaded_refs = st.file_uploader(
            upload_label, 
            type=["pdf", "png", "jpg", "jpeg"], 
            accept_multiple_files=True,
            key=f"uploader_{persona}_{int(time.time())}" # Add timestamp to reset key slightly if needed
        )
        
        if uploaded_refs and st.button("ğŸš€ è³‡æ–™ã‚’èª­ã¿è¾¼ã‚€ (Process Files)"):
             with st.spinner("è³‡æ–™ã‚’è§£æä¸­..."):
                try:
                    count = st.session_state.ai_interviewer.process_files(uploaded_refs)
                    st.success(f"{count}ä»¶ã®è³‡æ–™ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸï¼")
                    time.sleep(1)
                    st.rerun()
                except Exception as e:
                    st.error(f"èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

    # 3. Chat Interface
    st.divider()
    
    # History Display
    if not st.session_state.ai_interviewer.history:
        st.markdown(
            "ğŸ‘‹ **ã“ã‚“ã«ã¡ã¯ã€‚äº‹æ¥­ç¶™ç¶šåŠ›å¼·åŒ–è¨ˆç”»ã®ç­–å®šã‚’æ”¯æ´ã—ã¾ã™ã€‚**\n\n"
            "ã¾ãšã¯ä¸Šã®ã€Œè³‡æ–™ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã€ã‹ã‚‰è³‡æ–™ã‚’èª­ã¿è¾¼ã¾ã›ã‚‹ã‹ã€"
            "ä¸‹ã®å…¥åŠ›æ¬„ã‹ã‚‰ä¼šè©±ã‚’å§‹ã‚ã¦ãã ã•ã„ã€‚"
        )
    
    # Helper to render a single message
    def render_message(msg, current_persona):
        if not isinstance(msg, dict): return
        role = msg["role"]
        msg_persona = msg.get("persona", "Unknown")
        target_persona = msg.get("target_persona")
        
        # Filtering Logic
        visible = False
        if role == "user" and msg_persona == current_persona:
            visible = True
        elif role == "model" and target_persona == current_persona:
            visible = True
        
        if visible:
            avatar = "ğŸ¤–" if role == "model" else "ğŸ‘¤"
            if msg_persona == "çµŒå–¶è€…": avatar = "ğŸ‘¨â€ğŸ’¼"
            elif msg_persona == "å¾“æ¥­å“¡": avatar = "ğŸ‘·"
            elif msg_persona == "å•†å·¥ä¼šè·å“¡": avatar = "ğŸ§‘â€ğŸ«"
            elif msg_persona == "AI Concierge": avatar = "ğŸ¤–"
            
            with st.chat_message(role, avatar=avatar):
                if role == "user":
                    st.caption(f"{msg_persona}")
                
                # Sanitize content
                import re
                display_content = re.sub(r'<suggestions>.*?</suggestions>', '', msg["content"], flags=re.DOTALL).strip()
                st.markdown(display_content)

                # Capture suggestions (only from model)
                if role == "model":
                    match = re.search(r'<suggestions>(.*?)</suggestions>', msg["content"], flags=re.DOTALL)
                    if match:
                        try:
                            st.session_state._temp_suggestions = json.loads(match.group(1))
                        except:
                            pass

    # Reset temp suggestions
    if "_temp_suggestions" in st.session_state:
        del st.session_state["_temp_suggestions"]

    history = st.session_state.ai_interviewer.history
    loaded_count = st.session_state.get("loaded_msg_count", 0)

    # 1. Past History (Collapsible)
    if loaded_count > 0:
        with st.expander("ğŸ•’ éå»ã®ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’è¡¨ç¤º (Loaded History)", expanded=False):
            for i in range(loaded_count):
                if i < len(history):
                     render_message(history[i], persona)

    # 2. New Session History
    for i in range(loaded_count, len(history)):
        render_message(history[i], persona)
    
    # Retrieve suggestions
    current_dynamic_suggestions = st.session_state.get("_temp_suggestions", None)
        
    # --- Resume Guidance (System Message) ---
    # Only show if loaded history exists and no new messages have been added yet
    if loaded_count > 0 and len(history) == loaded_count:
        with st.container(border=True):
            st.markdown(f"**ğŸ¤– System Notification**")
            st.write("ä»¥å‰ã®ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚ç¶šãã‹ã‚‰å§‹ã‚ã¾ã—ã‚‡ã†ã€‚")
            
            # Simple missing info heuristic or static guidance
            if persona == "çµŒå–¶è€…":
                st.caption("ğŸ’¡ **ãƒ’ãƒ³ãƒˆ**: ä¼šç¤¾æ¡ˆå†…ã‚„äº‹æ¥­è¨ˆç”»æ›¸ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã¨ã€å…¥åŠ›ã®æ‰‹é–“ãŒçœã‘ã¾ã™ã€‚")
            elif persona == "å¾“æ¥­å“¡":
                st.caption("ğŸ’¡ **ãƒ’ãƒ³ãƒˆ**: ç¾å ´ã®å†™çœŸã‚„æ¥­å‹™ãƒãƒ‹ãƒ¥ã‚¢ãƒ«ãŒã‚ã‚Œã°ã€ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
            elif persona == "å•†å·¥ä¼šè·å“¡":
                st.caption("ğŸ’¡ **ãƒ’ãƒ³ãƒˆ**: åœ°åŸŸé˜²ç½è¨ˆç”»ã‚„ãƒã‚¶ãƒ¼ãƒ‰ãƒãƒƒãƒ—ã®æƒ…å ±ã‚’å…±æœ‰ã—ã¦ãã ã•ã„ã€‚")

    # --- Next Action Suggestions (Above Chat Input) ---
    st.caption("ğŸ’¡ **Quick Replies:** (ã‚¯ãƒªãƒƒã‚¯ã§è¿”ä¿¡ãƒ»ãƒˆãƒ”ãƒƒã‚¯é¸æŠ)")
    suggestion_cols = st.columns(3)
    
    # ç°¡æ˜“çš„ãªãƒšãƒ«ã‚½ãƒŠåˆ¥ææ¡ˆãƒªã‚¹ãƒˆ (Fallback)
    fallback_map = {
        "çµŒå–¶è€…": ["äº‹æ¥­ã®å¼·ã¿ã«ã¤ã„ã¦", "è‡ªç„¶ç½å®³ã¸ã®æ‡¸å¿µ", "é‡è¦ãªè¨­å‚™ãƒ»è³‡ç”£"],
        "å¾“æ¥­å“¡": ["ç·Šæ€¥æ™‚ã®é€£çµ¡ä½“åˆ¶", "é¿é›£çµŒè·¯ã®ç¢ºèª", "é¡§å®¢å¯¾å¿œãƒãƒ‹ãƒ¥ã‚¢ãƒ«"],
        "å•†å·¥ä¼šè·å“¡": ["ãƒã‚¶ãƒ¼ãƒ‰ãƒãƒƒãƒ—ç¢ºèª", "æå®³ä¿é™ºã®åŠ å…¥çŠ¶æ³", "åœ°åŸŸé˜²ç½è¨ˆç”»ã¨ã®é€£æº"]
    }
    
    # Use dynamic if available, else fallback
    # Note: 'current_dynamic_suggestions' needs to be initialized before loop if we want to be safe, 
    # but practically we can just init it here if not found.
    # Actually, Python variable scope in script means 'current_dynamic_suggestions' from loop might be unbound if loop didn't run or define it.
    # Better to initialize it before loop. 
    # BUT, since I can't edit "before loop" easily in this chunk without big context, 
    # I will use a safe access pattern or `locals().get`. 
    
    # Just to be safe and clean, let's use the fallback lookup.
    # Dynamic suggestion logic
    dynamic_list = None
    if current_dynamic_suggestions:
        if isinstance(current_dynamic_suggestions, dict):
            dynamic_list = current_dynamic_suggestions.get("suggested_topics")
        elif isinstance(current_dynamic_suggestions, list):
            dynamic_list = current_dynamic_suggestions

    final_suggestions = dynamic_list if dynamic_list else fallback_map.get(persona, [])
    
    suggested_prompt = None
    
    if final_suggestions:
        for i, topic in enumerate(final_suggestions[:3]):
            if suggestion_cols[i].button(f"ğŸ—£ï¸ {topic}", use_container_width=True):
                suggested_prompt = topic

    # User Input
    chat_input_prompt = st.chat_input(f"{persona}ã¨ã—ã¦å›ç­”ã‚’å…¥åŠ›...")
    
    # Determine which prompt to use (Button click takes precedence, but st.chat_input is usually None if button clicked)
    # Note: Streamlit execution model means if button clicked, rerun happens, chat_input is None.
    final_prompt = suggested_prompt if suggested_prompt else chat_input_prompt

    if final_prompt:
        with st.chat_message("user", avatar="ğŸ‘¤"):
            st.markdown(final_prompt)
        
        # Prepare metadata for context
        user_name = st.session_state.get("user_name_input", "")
        user_position = st.session_state.get("user_position_input", "")
        user_data = {"name": user_name, "position": user_position}

        with st.chat_message("model", avatar="ğŸ¤–"):
            with st.spinner("AI is thinking..."):
                response = st.session_state.ai_interviewer.send_message(
                    final_prompt, 
                    persona=persona,
                    user_data=user_data
                )
                st.markdown(response)
                
                # Feedback Toast
                st.toast("ğŸ“ ä¼šè©±ãƒ­ã‚°ã‚’æ›´æ–°ã—ã¾ã—ãŸ (Conversation Log Updated)", icon="âœ…")
                time.sleep(1) # Wait for toast to be seen briefly
                st.rerun()
elif mode == "Dashboard Mode (Progress)":
    # Navigation Header for Dashboard
    col_dash_head1, col_dash_head2 = st.columns([3, 1])
    with col_dash_head1:
        st.title("ğŸ“Š Progress Dashboard")
    with col_dash_head2:
        # 3-Way Back Navigation
        st.button("â¬…ï¸ çµŒå–¶è€…ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼", on_click=change_mode, args=("Chat Mode (Interview)", "çµŒå–¶è€…"), use_container_width=True)
        st.button("â¬…ï¸ å¾“æ¥­å“¡ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼", on_click=change_mode, args=("Chat Mode (Interview)", "å¾“æ¥­å“¡"), use_container_width=True)
        st.button("â¬…ï¸ å•†å·¥ä¼šè·å“¡ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼", on_click=change_mode, args=("Chat Mode (Interview)", "å•†å·¥ä¼šè·å“¡"), use_container_width=True)

    st.info("ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‹ã‚‰äº‹æ¥­è¨ˆç”»æ›¸ã®å®Œæˆåº¦ã‚’è‡ªå‹•åˆ¤å®šã—ã¾ã™ã€‚")
    
    from src.api.schemas import ApplicationRoot
    
    # è§£æå®Ÿè¡Œãƒœã‚¿ãƒ³
    if st.button("è§£æã™ã‚‹", type="primary", use_container_width=True):
        st.info("ğŸš€ Process Started: Checking Modules...")
        
        # ã‚¹ãƒ”ãƒŠãƒ¼ã‚’ä½¿ã‚ãšã«é€æ¬¡å®Ÿè¡Œã‚’è¡¨ç¤º
        status_placeholder = st.empty()
        
        try:
            status_placeholder.text("â³ Importing Schema...")
            from src.api.schemas import ApplicationRoot
            
            status_placeholder.text("â³ Calling Gemini API (This may take 10-20s)...")
            extracted_data = st.session_state.ai_interviewer.analyze_history()
            
            status_placeholder.text(f"âœ… API Returned. Data Type: {type(extracted_data)}")
            
            if extracted_data:
                status_placeholder.text("â³ Validating data with Pydantic...")
                try:
                    plan = ApplicationRoot.model_validate(extracted_data)
                    st.session_state.current_plan = plan
                    status_placeholder.success("ğŸ‰ Analysis Complete!")
                except Exception as val_e:
                    status_placeholder.error(f"Validation Error: {val_e}")
                    st.json(extracted_data)
                    st.stop()
                
                # --- Quality Check & Logic (Pending Migration) ---
                # issues = plan.check_quality()
                # missing_fields = []
                # if issues: ...
                
                st.session_state.ai_interviewer.set_focus_fields([]) # Clear focus for now
                
                time.sleep(1)
                st.rerun()

            else:
                status_placeholder.warning("âš ï¸ No data extracted (Empty result received).")

        except Exception as e:
            status_placeholder.error(f"âŒ Critical Error: {e}")
            st.exception(e)
    
    # è§£æçµæœã®è¡¨ç¤º (Updated for ApplicationRoot key mapping)
    if "current_plan" in st.session_state:
        plan: ApplicationRoot = st.session_state.current_plan
        from src.core.completion_checker import CompletionChecker
        
        # Run Analysis
        result = CompletionChecker.analyze(plan)
        
        # --- 1. Status Banner & Header ---
        st.divider()
        st.subheader("ğŸ“Š Plan Progress Dashboard")
        
        col_m1, col_m2 = st.columns([1, 4])
        with col_m1:
            st.metric(label="èªå®šå¯èƒ½æ€§ã‚¹ã‚³ã‚¢ (Score)", value=f"{result['total_score']} / 100", help="100ç‚¹ã§é›»å­ç”³è«‹ã®èªå®šè¦ä»¶ã‚’æº€ãŸã—ã¾ã™")
            
        with col_m2:
            st.caption("èªå®šã«å‘ã‘ãŸå¿…é ˆé …ç›®ã®å…¥åŠ›çŠ¶æ³ (Mandatory Requirements)")
            st.progress(result['mandatory_progress'])
            st.caption(f"å¿…é ˆé …ç›®ã®é”æˆç‡: {int(result['mandatory_progress']*100)}% å®Œäº†")
            
        # --- 2. Actionable Alerts (Missing Mandatory) ---
        if result['status'] != "success":
            with st.container(border=True): # Red/Error container simulation
                st.error("ğŸš¨ ç”³è«‹ã«å‘ã‘ã¦ã€ä»¥ä¸‹ã®å¿…é ˆé …ç›®ãŒä¸è¶³ã—ã¦ã„ã¾ã™")
                # Define a mapping for section names to Japanese
                section_map = {
                    "BasicInfo": "åŸºæœ¬æƒ…å ±",
                    "Goals": "äº‹æ¥­æ¦‚è¦ãƒ»ç›®æ¨™",
                    "ResponseProcedures": "åˆå‹•å¯¾å¿œ",
                    "Measures": "äº‹å‰å¯¾ç­–",
                    "FinancialPlan": "è³‡é‡‘è¨ˆç”»",
                    "PDCA": "æ¨é€²ä½“åˆ¶ (PDCA)"
                }
                for item in result['missing_mandatory']:
                    sec_label = section_map.get(item['section'], item['section'])
                    st.markdown(f"- **{sec_label}**: {item['msg']}")
                
                # Action Buttons (Simulation)
                # Action Buttons (Fixed Logic)
                if st.button("ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ã‚¢ãƒ¼ã«ä¸è¶³é …ç›®ã‚’èã„ã¦ã‚‚ã‚‰ã†", type="primary", key="btn_ask_missing"):
                    # 1. Set Focus
                    missing_msgs = [m['msg'] for m in result['missing_mandatory']]
                    st.session_state.ai_interviewer.set_focus_fields(missing_msgs)
                    
                    # 2. Inject System/User Trigger (Optional but helpful)
                    # We want the AI to speak first ideally, or context to be set.
                    # For now, just focus setting is enough as the System Prompt checks focus fields.
                    
                    # 3. Switch Navigation to Chat (Correctly restoring last active persona)
                    st.session_state.app_nav_selection = st.session_state.get("last_chat_nav", "çµŒå–¶è€…ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼")
                    
                    # 4. Rerun to effect change
                    st.rerun()

        elif result['recommended_progress'] < 1.0:
            st.success("âœ… ç”³è«‹è¦ä»¶ã¯ã‚¯ãƒªã‚¢ã—ã¦ã„ã¾ã™ï¼ (ã•ã‚‰ã«è¨ˆç”»ã‚’å¼·åŒ–ã—ã¾ã—ã‚‡ã†)")
            with st.expander("ğŸ’¡ ã•ã‚‰ãªã‚‹å“è³ªå‘ä¸Šã®ãƒ’ãƒ³ãƒˆ (Recommended Actions)", expanded=True):
                for sug in result['suggestions']:
                    st.info(f"Suggestion: {sug}")

        else:
             st.balloons()
             st.success("ğŸ† Perfect! è¨ˆç”»ã¯å®Œç’§ã§ã™ã€‚ç”³è«‹ã®æº–å‚™ãŒæ•´ã„ã¾ã—ãŸã€‚")

        # --- 3. Section Breakdown (Application Form Style: 6 Tabs) ---
        st.divider()
        
        # Dynamic Tab Labels (6-tab structure matching electronic application)
        tabs_labels = {
            "BasicInfo": "1ï¸âƒ£ åŸºæœ¬æƒ…å ±",
            "Goals": "2ï¸âƒ£ äº‹æ¥­æ¦‚è¦ãƒ»ç›®æ¨™",
            "Disaster": "3ï¸âƒ£ ç½å®³æƒ³å®š",
            "Response": "4ï¸âƒ£ åˆå‹•å¯¾å¿œ",
            "Measures": "5ï¸âƒ£ äº‹å‰å¯¾ç­–",
            "Finance": "6ï¸âƒ£ è³‡é‡‘ãƒ»æ¨é€²ä½“åˆ¶"
        }
        
        # Check missing items to add warning icons
        missing_sections = [m['section'] for m in result['missing_mandatory']]
        
        if "BasicInfo" in missing_sections: tabs_labels["BasicInfo"] += " âš ï¸"
        if "Goals" in missing_sections: tabs_labels["Goals"] += " âš ï¸"
        if "Goals" in missing_sections: tabs_labels["Disaster"] += " âš ï¸"  # Disaster is part of Goals
        if "ResponseProcedures" in missing_sections: tabs_labels["Response"] += " âš ï¸"
        if "Measures" in missing_sections: tabs_labels["Measures"] += " âš ï¸"
        if "FinancialPlan" in missing_sections or "PDCA" in missing_sections: tabs_labels["Finance"] += " âš ï¸"

        tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
            tabs_labels["BasicInfo"], 
            tabs_labels["Goals"], 
            tabs_labels["Disaster"],
            tabs_labels["Response"],
            tabs_labels["Measures"],
            tabs_labels["Finance"]
        ])
        
        # TAB 1: Basic Info
        with tab1:
            st.caption("ğŸ“‹ æ§˜å¼ç¬¬1 åŸºæœ¬æƒ…å ±")
            if plan.basic_info:
                bi = plan.basic_info
                full_address = f"{bi.address_pref or ''}{bi.address_city or ''}{bi.address_street or ''}{bi.address_building or ''}"
                
                display_data = {
                    "ä¼šç¤¾å": bi.corporate_name,
                    "ä»£è¡¨è€…": f"{bi.representative_title or ''} {bi.representative_name or ''}".strip(),
                    "è³‡æœ¬é‡‘": f"{bi.capital:,}å††" if bi.capital else "-",
                    "å¾“æ¥­å“¡æ•°": f"{bi.employees}å" if bi.employees else "-",
                    "éƒµä¾¿ç•ªå·": bi.address_zip,
                    "ä½æ‰€": full_address,
                    "æ¥­ç¨®": f"{bi.industry_major or ''} / {bi.industry_middle or ''}".strip(" /"),
                    "æ³•äººç•ªå·": bi.corporate_number or "-"
                }
                st.table([{"é …ç›®": k, "å†…å®¹": v} for k, v in display_data.items() if v and v != "-"])
            else:
                with st.container(border=True):
                    st.warning("âš ï¸ åŸºæœ¬æƒ…å ±ãŒæœªå…¥åŠ›ã§ã™ã€‚")
        
        # TAB 2: Overview & Goals
        with tab2:
            st.caption("ğŸ“‹ æ§˜å¼ç¬¬2 äº‹æ¥­æ´»å‹•ã®æ¦‚è¦ãƒ»å–çµ„ç›®çš„")
            
            with st.container(border=True):
                st.subheader("äº‹æ¥­æ´»å‹•ã®æ¦‚è¦")
                if plan.goals.business_overview:
                    st.info(plan.goals.business_overview)
                else:
                    st.error("ğŸš¨ äº‹æ¥­æ´»å‹•ã®æ¦‚è¦ãŒæœªå…¥åŠ›ã§ã™ã€‚")
                    st.caption("è‡ªç¤¾ã®äº‹æ¥­å†…å®¹ã€ã‚µãƒ—ãƒ©ã‚¤ãƒã‚§ãƒ¼ãƒ³ä¸Šã®å½¹å‰²ã€åœ°åŸŸçµŒæ¸ˆã¸ã®è²¢çŒ®ã‚’å…·ä½“çš„ã«è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚")
            
            with st.container(border=True):
                st.subheader("å–çµ„ç›®çš„")
                if plan.goals.business_purpose:
                    st.info(plan.goals.business_purpose)
                else:
                    st.warning("âš ï¸ å–çµ„ç›®çš„ãŒæœªå…¥åŠ›ã§ã™ã€‚")
        
        # TAB 3: Disaster Scenario
        with tab3:
            st.caption("ğŸ“‹ æ§˜å¼ç¬¬3 æƒ³å®šã•ã‚Œã‚‹è‡ªç„¶ç½å®³ç­‰ã®ãƒªã‚¹ã‚¯")
            
            with st.container(border=True):
                st.subheader("æƒ³å®šã™ã‚‹ç½å®³")
                if plan.goals.disaster_scenario.disaster_assumption:
                    st.info(plan.goals.disaster_scenario.disaster_assumption)
                else:
                    st.error("ğŸš¨ ç½å®³æƒ³å®šãŒæœªå…¥åŠ›ã§ã™ã€‚")
                    st.caption("ãƒã‚¶ãƒ¼ãƒ‰ãƒãƒƒãƒ—ã‚„J-SHISã‚’å‚ç…§ã—ã€ã€Œéœ‡åº¦â—‹â—‹ã€ã€Œæµ¸æ°´æ·±â—‹â—‹mã€ãªã©å…·ä½“çš„ãªæ•°å€¤ã‚’è¨˜è¼‰ã—ã¦ãã ã•ã„ã€‚")
            
            if plan.goals.disaster_scenario.impact_list:
                st.subheader(f"å½±éŸ¿è©•ä¾¡ï¼ˆ{len(plan.goals.disaster_scenario.impact_list)}ä»¶ï¼‰")
                st.table([i.model_dump() for i in plan.goals.disaster_scenario.impact_list])
            else:
                st.info("å½±éŸ¿è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ãªã— (ä»»æ„)")
        
        # TAB 4: First Response
        with tab4:
            st.caption(f"ğŸ“‹ æ§˜å¼ç¬¬4 åˆå‹•å¯¾å¿œæ‰‹é †ç­‰: {result['counts']['procedures']}ä»¶ç™»éŒ²æ¸ˆ")
            if plan.response_procedures:
                st.table([m.model_dump() for m in plan.response_procedures])
            else:
                with st.container(border=True):
                    st.error("ğŸš¨ åˆå‹•å¯¾å¿œãŒæœªç™»éŒ²ã§ã™ã€‚")
                    st.caption("ç½å®³ç™ºç”Ÿç›´å¾Œã«èª°ãŒä½•ã‚’ã™ã‚‹ã‹ï¼ˆä¾‹ï¼šå®‰å¦ç¢ºèªã€é¿é›£èª˜å°ï¼‰ã‚’æ±ºã‚ã¦ãã ã•ã„ã€‚")
        
        # TAB 5: Measures
        with tab5:
            st.caption(f"ğŸ“‹ æ§˜å¼ç¬¬5 å¹³æ™‚ã®å–çµ„: {result['counts']['measures']}ä»¶ç™»éŒ²æ¸ˆ")
            if plan.measures:
                st.table([m.model_dump() for m in plan.measures])
            else:
                with st.container(border=True):
                    st.error("ğŸš¨ äº‹å‰å¯¾ç­–ãŒã¾ã ç™»éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
                    st.caption("ãƒªã‚¹ã‚¯ã‚’è»½æ¸›ã™ã‚‹ãŸã‚ã®å…·ä½“çš„ãªå¯¾ç­–ï¼ˆä¾‹ï¼šåœ¨åº«åˆ†æ•£ã€æ£šã®å›ºå®šã€ã‚¯ãƒ©ã‚¦ãƒ‰ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ï¼‰ã‚’ç™»éŒ²ã—ã¦ãã ã•ã„ã€‚")
        
        # TAB 6: Finance & PDCA
        with tab6:
            st.caption("ğŸ“‹ æ§˜å¼ç¬¬6 è³‡é‡‘è¨ˆç”»ãƒ»æ¨é€²ä½“åˆ¶")
            
            with st.container(border=True):
                st.subheader("ğŸ’° è³‡é‡‘è¨ˆç”»")
                if plan.financial_plan.items:
                    st.table([i.model_dump() for i in plan.financial_plan.items])
                else:
                    st.warning("âš ï¸ è³‡é‡‘è¨ˆç”»ãŒæœªå…¥åŠ›ã§ã™ã€‚")
                    st.caption("å¾©æ—§ã«ã‹ã‹ã‚‹è²»ç”¨ã®ç›®å®‰ã¨ã€ãã®èª¿é”æ–¹æ³•ï¼ˆä¿é™ºã€è‡ªå·±è³‡é‡‘ã€å€Ÿå…¥ãªã©ï¼‰ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚")
            
            with st.container(border=True):
                st.subheader("ğŸ› ï¸ è¨­å‚™ãƒªã‚¹ãƒˆ (ç¨åˆ¶å„ªé‡)")
                if plan.equipment.items:
                    st.table([i.model_dump() for i in plan.equipment.items])
                else:
                    st.info("è¨­å‚™ãƒªã‚¹ãƒˆãªã— (ä»»æ„)")
            
            with st.container(border=True):
                st.subheader("ğŸ”„ æ¨é€²ä½“åˆ¶ãƒ»è¨“ç·´")
                pdca_data = {
                    "ç®¡ç†ä½“åˆ¶": plan.pdca.management_system or "-",
                    "è¨“ç·´ãƒ»æ•™è‚²": plan.pdca.training_education or "-"
                }
                st.table([{"é …ç›®": k, "å†…å®¹": v} for k, v in pdca_data.items()])

        # --- 4. Sidebar Tools (Injected here dynamically or rely on static layout) ---
        # Note: Sidebar is already rendered at top of script. We can add to it here or just leave as is.
        # Adding a dedicated "Tools" expander in main area for visibility
        with st.expander("ğŸ› ï¸ ãŠå½¹ç«‹ã¡ãƒ„ãƒ¼ãƒ« (External Tools)"):
            c1, c2, c3 = st.columns(3)
            c1.link_button("ğŸŒ ãƒã‚¶ãƒ¼ãƒ‰ãƒãƒƒãƒ—ãƒãƒ¼ã‚¿ãƒ«", "https://disaportal.gsi.go.jp/")
            c2.link_button("ğŸ“‰ J-SHIS åœ°éœ‡äºˆæ¸¬", "https://www.j-shis.bosai.go.jp/")
            c3.link_button("ğŸ’´ BCPãƒãƒ¼ã‚¿ãƒ« (ãƒªã‚¹ã‚¯ãƒ•ã‚¡ã‚¤ãƒŠãƒ³ã‚¹ç­‰)", "https://kyoujinnka.smrj.go.jp/")

    else:
        st.info("â˜ï¸ Click the button to analyze current chat history.")

    st.divider()
    with st.expander("Show Raw Chat History"):
        st.json(st.session_state.ai_interviewer.history)

elif mode == "Main Consensus Room (Resolution)":
    st.title("âš–ï¸ Consensus Room (å…¨ä½“åˆæ„)")
    st.caption("å„ãƒšãƒ«ã‚½ãƒŠã®æ„è¦‹ã‚’èª¿æ•´ã—ã€æœ€çµ‚çš„ãªæ–¹é‡ã‚’æ±ºå®šã—ã¾ã™ã€‚")
    
    # Conflict Detection
    with st.expander("ğŸ§ çŸ›ç›¾ãƒ»æœªåˆæ„äº‹é …ã®æ¤œçŸ¥ (Conflict Detection)", expanded=True):
        if st.button("çŸ›ç›¾ã‚’å†ã‚¹ã‚­ãƒ£ãƒ³ã™ã‚‹", type="primary"):
            with st.spinner("Analyzing conflicts..."):
                conflicts = st.session_state.ai_interviewer.detect_conflicts()
                st.session_state._conflicts_cache = conflicts
        
        # Retrieve cache
        current_conflicts_data = st.session_state.get("_conflicts_cache", {})
        current_conflicts = current_conflicts_data.get("conflicts", [])
        
        if current_conflicts:
            st.warning(f"{len(current_conflicts)}ä»¶ã®çŸ›ç›¾ã¾ãŸã¯æœªåˆæ„äº‹é …ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚")
            for i, c in enumerate(current_conflicts):
                st.markdown(f"#### {i+1}. {c.get('topic', 'Topic')}")
                col1, col2 = st.columns(2)
                with col1:
                    st.info(f"**A: {c.get('persona_A')}**\n\n{c.get('statement_A')}")
                with col2:
                    st.info(f"**B: {c.get('persona_B')}**\n\n{c.get('statement_B')}")
                st.success(f"ğŸ’¡ **AI Suggestion**: {c.get('suggestion')}")
                st.divider()
        else:
             st.info("çŸ›ç›¾ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ (æœªã‚¹ã‚­ãƒ£ãƒ³ã¾ãŸã¯è§£æ¶ˆæ¸ˆã¿)")

    st.divider()
    st.subheader("ğŸ’¬ å…¨ä½“æ–¹é‡ã®æ±ºå®š")
    
    # Chat History
    history = st.session_state.ai_interviewer.history
    
    # Show history using rendered helper
    for i in range(len(history)):
         render_message(history[i], "ç·åˆèª¿æ•´å½¹") 
    
    # Input
    if prompt := st.chat_input("å…¨ä½“æ–¹é‡ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ (ä¾‹: é¿é›£å ´æ‰€ã¯é«˜å°ã®å…¬åœ’ã¨ã—ã¾ã™)"):
         with st.chat_message("user", avatar="ğŸ‘¤"):
            st.markdown(prompt)
         
         # Metadata
         user_name = st.session_state.get("user_name_input", "")
         user_position = st.session_state.get("user_position_input", "")
         user_data = {"name": user_name, "position": user_position}
         
         with st.chat_message("model", avatar="ğŸ¤–"):
            with st.spinner("AI Facilitator is recording..."):
                response = st.session_state.ai_interviewer.send_message(
                    prompt, 
                    persona="ç·åˆèª¿æ•´å½¹",
                    user_data=user_data
                )
                st.markdown(response)
                st.rerun()
