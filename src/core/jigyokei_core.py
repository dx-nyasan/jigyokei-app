import os
import json
import google.generativeai as genai
import streamlit as st

class AIInterviewer:
    """
    Gemini 2.5 Flash ã‚’ä½¿ç”¨ã—ãŸãƒãƒ£ãƒƒãƒˆç®¡ç†ã‚¯ãƒ©ã‚¹ã€‚
    å±¥æ­´ã®ä¿æŒã¨ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®é©ç”¨ã‚’è¡Œã†ã€‚
    (Updated for Phase 3: Analysis Features)
    """
    def __init__(self):
        self.history = []
        self.uploaded_file_refs = [] # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®å‚ç…§ä¿æŒç”¨
        self.focus_fields = [] # AIãŒé‡ç‚¹çš„ã«èãã¹ãä¸è¶³é …ç›®ã®ãƒªã‚¹ãƒˆ
        
        # åŸºæœ¬ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        self.base_system_prompt = """
        ã‚ãªãŸã¯æ—¥æœ¬ã®ä¸­å°ä¼æ¥­ã‚’æ”¯æ´ã™ã‚‹ã€Œäº‹æ¥­ç¶™ç¶šåŠ›å¼·åŒ–è¨ˆç”»ç­–å®šæ”¯æ´ã‚³ãƒ³ã‚·ã‚§ãƒ«ã‚¸ãƒ¥ã€ã§ã™ã€‚
        ãƒ¦ãƒ¼ã‚¶ãƒ¼ï¼ˆçµŒå–¶è€…ãƒ»å¾“æ¥­å“¡ãƒ»å•†å·¥ä¼šè·å“¡ï¼‰ã«å¯¾ã—ã€ä»¥ä¸‹ã®ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã«å¾“ã£ã¦ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼ã‚’è¡Œã„ã€è¨ˆç”»ç­–å®šã‚’æ”¯æ´ã—ã¦ãã ã•ã„ã€‚

        ã€æœ€é‡è¦æŒ‡é‡ï¼šè³‡æ–™èª­ã¿è¾¼ã¿ãƒ•ã‚¡ãƒ¼ã‚¹ãƒˆã€‘
        ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰è³‡æ–™ï¼ˆPDFã‚„ç”»åƒï¼‰ãŒæä¾›ã•ã‚ŒãŸå ´åˆã€**çµ¶å¯¾ã«**ä»¥ä¸‹ã®æ‰‹é †ã‚’å®ˆã‚‹ã“ã¨ï¼š
        1. **ã¾ãšè³‡æ–™ã‚’èª­ã‚€**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸ã®è³ªå•ã‚’é–‹å§‹ã™ã‚‹å‰ã«ã€ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸè³‡æ–™ã‚’éš…ã€…ã¾ã§èª­ã¿è¾¼ã‚“ã§ãã ã•ã„ã€‚
        2. **æƒ…å ±ã®æŠ½å‡ºã¨ç¢ºèª**: è³‡æ–™ã«è¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹æƒ…å ±ï¼ˆä¼æ¥­æ¦‚è¦ã€äº‹æ¥­å†…å®¹ã€è¨­å‚™ã€ãƒªã‚¹ã‚¯ã€é€£çµ¡ç¶²ãªã©ï¼‰ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚
        3. **ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸ã®æç¤º**: ã€Œã„ãŸã ã„ãŸè³‡æ–™ã‹ã‚‰ã€ä»¥ä¸‹ã®æƒ…å ±ã‚’èª­ã¿å–ã‚Šã¾ã—ãŸã€ã¨æç¤ºã—ã€ã€Œã“ã®å†…å®¹ã§ç™»éŒ²ã—ã¦ã‚ˆã‚ã—ã„ã§ã™ã‹ï¼Ÿã€ã¨ç¢ºèªã‚’æ±‚ã‚ã¦ãã ã•ã„ã€‚
        4. **é‡è¤‡è³ªå•ã®ç¦æ­¢**: **è³‡æ–™ã«æ›¸ã„ã¦ã‚ã‚‹ã“ã¨ã‚’ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«è³ªå•ã—ã¦ã¯ã„ã‘ã¾ã›ã‚“ã€‚** è³‡æ–™ã«ãªã„ã€ã¾ãŸã¯èª­ã¿å–ã‚Œãªã‹ã£ãŸå¿…é ˆé …ç›®ã«ã¤ã„ã¦ã®ã¿è³ªå•ã—ã¦ãã ã•ã„ã€‚

        ã€åŸºæœ¬ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã€‘
        - ç›¸æ‰‹ã®ãƒšãƒ«ã‚½ãƒŠï¼ˆçµŒå–¶è€…ã€å¾“æ¥­å“¡ã€å•†å·¥ä¼šè·å“¡ï¼‰ã«åˆã‚ã›ã¦å£èª¿ã‚„ç€çœ¼ç‚¹ã‚’èª¿æ•´ã—ã¦ãã ã•ã„ã€‚
        - å°‚é–€ç”¨èªã¯é¿ã‘ã€åˆ†ã‹ã‚Šã‚„ã™ã„è¨€è‘‰ã§è©±ã—ã‹ã‘ã¦ãã ã•ã„ã€‚
        - ä¸€åº¦ã«è¤‡æ•°ã®è³ªå•ã‚’ã›ãšã€ä¸€ã¤ãšã¤ç¢ºèªã—ã¦ãã ã•ã„ã€‚
        """

        # Streamlit Secrets ã¾ãŸã¯ ç’°å¢ƒå¤‰æ•°ã‹ã‚‰APIã‚­ãƒ¼ã‚’å–å¾—
        api_key = None
        try:
            api_key = st.secrets["GOOGLE_API_KEY"]
        except Exception:
            api_key = os.getenv("GOOGLE_API_KEY")

        if api_key:
            genai.configure(api_key=api_key)
            try:
                # model_name ã‚’ gemini-2.5-flash ã«å›ºå®š
                self.model = genai.GenerativeModel(
                    model_name='gemini-2.5-flash',
                    system_instruction=self.base_system_prompt
                )
                self.chat_session = self.model.start_chat(history=[])
            except Exception as e:
                st.error(f"Failed to initialize Gemini model: {e}")
                self.model = None
        else:
            self.model = None
            st.error("Google API Key not found. Please set it in Streamlit Secrets.")

    def set_focus_fields(self, fields: list):
        """
        AIãŒé‡ç‚¹çš„ã«èãã¹ãé …ç›®ã‚’è¨­å®šã™ã‚‹ã€‚
        ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã§ã®è§£æçµæœã«åŸºã¥ã„ã¦å‘¼ã³å‡ºã•ã‚Œã‚‹ã“ã¨ã‚’æƒ³å®šã€‚
        """
        self.focus_fields = fields

    def process_files(self, uploaded_files):
        """
        Streamlitã®UploadedFileãƒªã‚¹ãƒˆã‚’å—ã‘å–ã‚Šã€Gemini File APIã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€
        ãƒãƒ£ãƒƒãƒˆã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ç™»éŒ²ã™ã‚‹ã€‚
        """
        if not self.model:
            return 0
            
        import tempfile
        import time
        
        count = 0
        new_files = []
        
        for up_file in uploaded_files:
            # MIMEã‚¿ã‚¤ãƒ—ç°¡æ˜“åˆ¤å®š
            mime_type = up_file.type
            if not mime_type:
                # æ‹¡å¼µå­ã‹ã‚‰æ¨æ¸¬ï¼ˆæœ€ä½é™ï¼‰
                ext = up_file.name.split('.')[-1].lower()
                if ext in ['png', 'jpg', 'jpeg']: mime_type = 'image/jpeg'
                elif ext == 'pdf': mime_type = 'application/pdf'
                else: mime_type = 'application/pdf' # Default

            try:
                # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
                with tempfile.NamedTemporaryFile(delete=False, suffix=f".{up_file.name.split('.')[-1]}") as tmp:
                    tmp.write(up_file.getvalue())
                    tmp_path = tmp.name
                
                # Geminiã¸ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
                g_file = genai.upload_file(path=tmp_path, mime_type=mime_type, display_name=up_file.name)
                
                # Activeå¾…ã¡ï¼ˆFlashã¯æ—©ã„ãŒå¿µã®ãŸã‚ï¼‰
                # while g_file.state.name == "PROCESSING":
                #     time.sleep(1)
                #     g_file = genai.get_file(g_file.name)
                
                self.uploaded_file_refs.append(g_file)
                new_files.append(g_file)
                count += 1
                
                # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                os.unlink(tmp_path)
                
            except Exception as e:
                print(f"File upload failed: {e}")
                st.error(f"Error uploading {up_file.name}: {e}")

        # ãƒãƒ£ãƒƒãƒˆã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æŠ•å…¥
        if new_files:
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã¯è¦‹ãˆãªã„ãŒã€ãƒ¢ãƒ‡ãƒ«ã«ã¯ã€Œè³‡æ–™ã‚’æ¸¡ã™ã€ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
            files_prompt = """
            ã€ã‚·ã‚¹ãƒ†ãƒ æŒ‡ç¤ºã€‘
            ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰å‚è€ƒè³‡æ–™ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã—ãŸã€‚ã“ã‚Œã‚‰ã‚’èª­ã¿è¾¼ã¿ã€äº‹æ¥­ç¶™ç¶šåŠ›å¼·åŒ–è¨ˆç”»ï¼ˆBCPï¼‰ã®å„é …ç›®ï¼ˆä¼æ¥­åŸºæœ¬æƒ…å ±ã€äº‹æ¥­å†…å®¹ã€è¨­å‚™ã€ãƒªã‚¹ã‚¯å¯¾ç­–ãªã©ï¼‰ã«è©²å½“ã™ã‚‹æƒ…å ±ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚
            
            æŠ½å‡ºå¾Œã¯ã€ä»¥ä¸‹ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ç¢ºèªã—ã¦ãã ã•ã„ï¼š
            ã€Œä»¥ä¸‹ã®æƒ…å ±ã‚’è³‡æ–™ã‹ã‚‰èª­ã¿å–ã‚Šã¾ã—ãŸã€‚ç™»éŒ²ã—ã¦ã‚ˆã‚ã—ã„ã§ã™ã‹ï¼Ÿ
            - é …ç›®å: å€¤ (å‡ºå…¸: è³‡æ–™å)
            ...ã€
            """
            try:
                # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨ã—ã¦ãƒ•ã‚¡ã‚¤ãƒ«å‚ç…§ã‚’é€ä¿¡
                self.chat_session.send_message([files_prompt] + new_files)
                
                # AIã®å¿œç­”ï¼ˆã€Œèª­ã¿è¾¼ã¿ã¾ã—ãŸã€ï¼‰ã‚’å±¥æ­´ã«è¿½åŠ ï¼ˆå®Ÿéš›ã¯send_messageã®è¿”ç­”ã ãŒä»Šå›ã¯æ“¬ä¼¼çš„ã«ï¼‰
                self.history.append({
                    "role": "model",
                    "content": f"ğŸ“ {count}ä»¶ã®è³‡æ–™ï¼ˆ{', '.join([f.display_name for f in new_files])}ï¼‰ã‚’å—ã‘å–ã‚Šã¾ã—ãŸã€‚\nå†…å®¹ã‚’ç¢ºèªã—ã¦ã€åˆ†ã‹ã‚‹éƒ¨åˆ†ã¯å…¥åŠ›ã‚’çœç•¥ã§ãã‚‹ã‚ˆã†ã«ã—ã¾ã™ã­ã€‚",
                    "persona": "AI Concierge"
                })
            except Exception as e:
                 st.error(f"Error sending files to chat: {e}")

        return count

    def send_message(self, user_input: str, persona: str = "çµŒå–¶è€…") -> str:
        if not self.model:
            return "Error: API Key is missing or model initialization failed."

        # å±¥æ­´ã¸ã®è¿½åŠ ï¼ˆã‚¢ãƒ—ãƒªè¡¨ç¤ºç”¨ï¼‰
        self.history.append({
            "role": "user", 
            "content": user_input,
            "persona": persona
        })
        
        # å®Ÿéš›ã«APIã«é€ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ§‹ç¯‰
        # Gap-Fillingã®ãŸã‚ã®èª˜å°ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ä»˜ä¸ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã¯è¦‹ãˆãªã„ï¼‰
        actual_prompt = user_input
        if self.focus_fields:
            fields_str = ", ".join(self.focus_fields)
            actual_prompt += f"""
            
            [System Instruction for AI]
            ç¾åœ¨ã€ä»¥ä¸‹ã®é …ç›®ãŒã¾ã å…¥åŠ›ã•ã‚Œã¦ã„ã¾ã›ã‚“: {fields_str}
            
            ã€è¡Œå‹•æŒ‡é‡ã€‘
            1. **æ–‡è„ˆå„ªå…ˆ**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç›´å‰ã®ç™ºè¨€ãŒã€ä¸Šè¨˜ã®æœªå…¥åŠ›é …ç›®ï¼ˆä¾‹ï¼šä½æ‰€ï¼‰ã«é–¢é€£ã™ã‚‹å ´åˆã€**ãã®é …ç›®ãã®ã‚‚ã®**ã«ã¤ã„ã¦è³ªå•ã—ã¦ãã ã•ã„ã€‚ï¼ˆä¾‹ï¼šã€Œä½æ‰€ã¯ã¾ã ç™»éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã”ä½æ‰€ã‚’æ•™ãˆã¦ã„ãŸã ã‘ã¾ã™ã‹ï¼Ÿã€ï¼‰
            2. **è‡ªç„¶ãªèª˜å°**: æ–‡è„ˆã«é–¢é€£ãŒãªã„å ´åˆã®ã¿ã€ä¸Šè¨˜ãƒªã‚¹ãƒˆã‹ã‚‰æœ€ã‚‚é‡è¦ã¨æ€ã‚ã‚Œã‚‹ã‚‚ã®ã‚’1ã¤é¸ã³ã€è‡ªç„¶ã«è©±é¡Œã‚’æŒ¯ã£ã¦ãã ã•ã„ã€‚
            3. **å”çªã•ã®å›é¿**: æ©Ÿæ¢°çš„ã«ãƒªã‚¹ãƒˆã‚’æ¶ˆåŒ–ã™ã‚‹ã®ã§ã¯ãªãã€ä¼šè©±ã®æµã‚Œã‚’ç¶­æŒã—ã¦ãã ã•ã„ã€‚
            """
        
        try:
            # Geminiã¸ã®é€ä¿¡
            response = self.chat_session.send_message(actual_prompt)
            text_response = response.text
            
            self.history.append({
                "role": "model",
                "content": text_response,
                "persona": "AI Concierge"
            })
            return text_response
            
        except Exception as e:
            error_msg = f"ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã€ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
            self.history.append({"role": "model", "content": error_msg})
            return error_msg

    def analyze_history(self) -> dict:
        """
        ç¾åœ¨ã®ä¼šè©±å±¥æ­´ã‚’åˆ†æã—ã€JigyokeiPlanã‚¹ã‚­ãƒ¼ãƒã«é©åˆã™ã‚‹JSONã‚’ç”Ÿæˆã™ã‚‹ã€‚
        """
        if not self.history:
            return {}

        # å±¥æ­´ã‚’ãƒ†ã‚­ã‚¹ãƒˆåŒ–
        history_text = ""
        for msg in self.history:
            role = msg["role"]
            content = msg["content"]
            persona = msg.get("persona", "")
            history_text += f"[{role} ({persona})]: {content}\n"

        prompt = f"""
        ã‚ãªãŸã¯äº‹æ¥­ç¶™ç¶šåŠ›å¼·åŒ–è¨ˆç”»ã®ç­–å®šæ”¯æ´AIã§ã™ã€‚
        ä»¥ä¸‹ã®ä¼šè©±å±¥æ­´ã‹ã‚‰ã€äº‹æ¥­è¨ˆç”»æ›¸ã®ä½œæˆã«å¿…è¦ãªæƒ…å ±ã‚’æŠ½å‡ºã—ã€JSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
        
        ã€æŠ½å‡ºãƒ«ãƒ¼ãƒ«ã€‘
        1. ä»¥ä¸‹ã®JSONã‚¹ã‚­ãƒ¼ãƒã«å¾“ã†ã“ã¨ã€‚
        2. æƒ…å ±ãŒãªã„é …ç›®ã¯ null ã¾ãŸã¯ "æœªè¨­å®š" ã¨ã™ã‚‹ã€‚
        3. æ¨æ¸¬ã¯ã›ãšã€ä¼šè©±ã«å‡ºã¦ããŸäº‹å®Ÿã®ã¿ã‚’æŠ½å‡ºã™ã‚‹ã“ã¨ã€‚

        ã€ä¼šè©±å±¥æ­´ã€‘
        {history_text}

        ã€å‡ºåŠ›ã‚¹ã‚­ãƒ¼ãƒã€‘
        {{
            "basic_info": {{
                "company_name": "ä¼æ¥­å",
                "representative_name": "ä»£è¡¨è€…å",
                "address": "ä½æ‰€",
                "phone_number": "é›»è©±ç•ªå·",
                "business_type": "æ¥­ç¨®"
            }},
            "business_content": {{
                "target_customers": "èª°ã«",
                "products_services": "ä½•ã‚’",
                "delivery_methods": "ã©ã®ã‚ˆã†ã«",
                "core_competence": "å¼·ã¿"
            }},
            "disaster_risks": [
                {{ "risk_type": "ç½å®³ã®ç¨®é¡", "impact_description": "å½±éŸ¿" }}
            ],
            "pre_disaster_measures": [
                {{ "item": "å¯¾ç­–é …ç›®", "content": "å†…å®¹", "in_charge": "æ‹…å½“", "deadline": "æ™‚æœŸ" }}
            ],
            "post_disaster_measures": [
                {{ "item": "å¯¾å¿œé …ç›®", "content": "å†…å®¹", "in_charge": "æ‹…å½“", "deadline": "æ™‚æœŸ" }}
            ]
        }}
        """

        try:
            response = self.model.generate_content(prompt)
            text = response.text
            import re
            json_match = re.search(r'```json\s*(.*?)\s*```', text, re.DOTALL)
            if json_match:
                return json.loads(json_match.group(1))
            else:
                return json.loads(text)
        except Exception as e:
            print(f"Analysis failed: {e}")
            return {}

    def merge_history(self, new_history: list):
        """
        æ–°ã—ã„å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã‚’ç¾åœ¨ã®å±¥æ­´ã«çµ±åˆï¼ˆãƒãƒ¼ã‚¸ï¼‰ã™ã‚‹ã€‚
        å˜ç´”ãªè¿½è¨˜ï¼ˆextendï¼‰ã‚’è¡Œã†ãŒã€å°†æ¥çš„ã«ã¯ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ç­‰ã«ã‚ˆã‚‹ã‚½ãƒ¼ãƒˆã‚‚æ¤œè¨å¯èƒ½ã€‚
        """
        # é‡è¤‡æ’é™¤ãƒ­ã‚¸ãƒƒã‚¯ã‚’å«ã‚ã‚‹ã¨ãªãŠè‰¯ã„ãŒã€ã¾ãšã¯å˜ç´”çµåˆ
        # ä¼šè©±ã®æµã‚ŒãŒä¸è‡ªç„¶ã«ãªã‚‹ãƒªã‚¹ã‚¯ã¯ã‚ã‚‹ãŒã€Geminiã¯ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦å‡¦ç†ã™ã‚‹ã“ã¨ã‚’æœŸå¾…
        self.history.extend(new_history)
        
        # Geminiã‚»ãƒƒã‚·ãƒ§ãƒ³ã®å†æ§‹ç¯‰ï¼ˆå±¥æ­´ãŒå¤‰ã‚ã£ãŸãŸã‚å¿…é ˆï¼‰
        self._rebuild_gemini_session()

    def _rebuild_gemini_session(self):
        """
        ç¾åœ¨ã® self.history ã«åŸºã¥ã„ã¦ Gemini ã®ãƒãƒ£ãƒƒãƒˆã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’å†æ§‹ç¯‰ã™ã‚‹
        """
        if not self.model:
            return

        gemini_history = []
        for msg in self.history:
            role = "user" if msg["role"] == "user" else "model"
            # Gemini history format: role must be 'user' or 'model'
            gemini_history.append({
                "role": role,
                "parts": [msg["content"]]
            })
        
        try:
            self.chat_session = self.model.start_chat(history=gemini_history)
        except Exception as e:
            print(f"Failed to rebuild gemini session: {e}")
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ç©ºã§åˆæœŸåŒ–
            self.chat_session = self.model.start_chat(history=[])

    def load_history(self, history_data: list, merge: bool = False):
        """
        å¤–éƒ¨ã‹ã‚‰å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€ã€‚
        merge=Trueã®å ´åˆã€æ—¢å­˜ã®å±¥æ­´ã‚’ä¿æŒã—ãŸã¾ã¾è¿½åŠ ã™ã‚‹ï¼ˆãƒã‚¹ã‚¿ãƒ¼ãƒãƒ£ãƒƒãƒˆåŒ–ï¼‰ã€‚
        """
        if merge:
            self.merge_history(history_data)
        else:
            self.history = history_data
            self._rebuild_gemini_session()
